{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Map987/BilibiliSummary/blob/main/colab%E4%B8%8B%E8%BD%BD%E6%96%B9%E6%A1%88_share1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #### è¯´æ˜ï¼šå·¦è¾¹æŸ¥çœ‹ç›®å½•ï¼Œæ–‡ä»¶åˆ—è¡¨ï¼Œå³é”®å¯å¤åˆ¶æ–‡ä»¶ï¼ˆå¤¹ï¼‰è·¯å¾„"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0f3XDzY3gxd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # è°·æ­Œäº‘ç›˜æŒ‚è½½åˆ°Colabç¯å¢ƒï¼ˆå¿…é€‰ï¼‰\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!apt-get -y install -qq aria2"
      ],
      "metadata": {
        "id": "-KVukWdRIsRE",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ï¼ˆè°·æ­Œå’ŒOneDriveï¼‰ä¸‹è½½"
      ],
      "metadata": {
        "id": "D5qR921rEhWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # ï¼ˆè°·æ­Œäº‘ç›˜ï¼‰æ–‡ä»¶å¤¹ä¸‹è½½ã€å•æ–‡ä»¶ä¸‹è½½\n",
        "import os\n",
        "folder = \"/content/\" #@param {type:\"string\"}\n",
        "folder = os.path.join(folder, \"\")\n",
        "url = \"https://drive.google.com/drive/folders/xxx\" #@param {type:\"string\"}\n",
        "\n",
        "if \"/folders/\" in url:\n",
        "  !gdown --fuzzy {url} -O {folder} --folder\n",
        "else:\n",
        "  !gdown --fuzzy {url} -O {folder}"
      ],
      "metadata": {
        "id": "DTrKyXigeiCC",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # ï¼ˆOneDriveï¼‰æ–‡ä»¶å¤¹ä¸‹è½½ï¼Œå•æ–‡ä»¶ä¸‹è½½\n",
        "import os\n",
        "import re\n",
        "import requests\n",
        "import urllib.parse\n",
        "!apt-get -y install -qq aria2\n",
        "def onelink1(string):\n",
        "    !echo -n \"{string}\"|base64|sed \"s/=$//;s/\\//\\_/g;s/\\+/\\-/g;s/^/https:\\/\\/api\\.onedrive\\.com\\/v1\\.0\\/shares\\/u\\!/;s/$/\\/root\\/content/\";\n",
        "# å°†åˆ†äº«é“¾æ¥è½¬æ¢ä¸ºç›´é“¾ä¸‹è½½é“¾æ¥\n",
        "def onelink(string):\n",
        "    cmd = f\"echo -n '{string}' | base64 | sed 's/=$//;s/\\//_/g;s/+/\\\\-/g;s/^/https:\\\\/\\\\/api.onedrive.com\\\\/v1.0\\\\/shares\\\\/u!/;s/$/\\\\/root\\\\/content/'\"\n",
        "    return [os.popen(cmd).read().strip()]\n",
        "def get_download_url(url):\n",
        "    response = requests.get(url, allow_redirects=False)\n",
        "    redirect_url = response.headers.get('location')\n",
        "    # ä»åŸé“¾æ¥ä¸­æå–å‡ºç¬¬ä¸€éƒ¨åˆ†ã€ç¬¬äºŒéƒ¨åˆ†å’Œç¬¬ä¸‰éƒ¨åˆ†\n",
        "    parts = redirect_url.split(\"/\")\n",
        "    first_part = \"/\".join(parts[:3])\n",
        "    second_part = \"/\".join(parts[3:7])\n",
        "    third_part = \"download.aspx?SourceUrl=\" + \"/\".join(parts[7].split(\"=\")[1].split(\"&\")[:-1])\n",
        "    # ç»„åˆæˆç›®æ ‡é“¾æ¥\n",
        "    target_link = first_part + \"/\" + second_part + \"/\" + third_part\n",
        "    return target_link\n",
        "def get_download_url_sp(url,cookie):\n",
        "    headers = {\n",
        "        'Cookie': cookie\n",
        "    }\n",
        "    response = requests.get(url, allow_redirects=False,headers=headers)\n",
        "    redirect_url = response.headers.get('location')\n",
        "    decoded_url = urllib.parse.unquote(redirect_url)\n",
        "    url = decoded_url\n",
        "    base_path = '/'.join(url.split('/')[:5]) + '/'\n",
        "    base_path2 = '/'.join(url.split('/')[:7]) + '/'\n",
        "    # ä»åŸé“¾æ¥ä¸­è·å–æ–‡ä»¶å¤¹è·¯å¾„\n",
        "    folder_path = url.split(\"id=\")[1].split(\"&\")[0]\n",
        "    site_path = '/'.join((url.split(\"id=\")[1]).split('/')[:4])\n",
        "    root_folder_param = \"&RootFolder=\" + folder_path\n",
        "    get_list_using_path_param = f\"@a1='{site_path}'\"\n",
        "    try_new_experience_single_param = \"TryNewExperienceSingle=TRUE\"\n",
        "    post_url = base_path+\"_api/web/GetListUsingPath(DecodedUrl=@a1)/RenderListDataAsStream?\" + get_list_using_path_param + root_folder_param + \"&\" + try_new_experience_single_param\n",
        "    response = requests.post(post_url,headers=headers)\n",
        "    response_dict = response.json()\n",
        "    download_urls = []\n",
        "    file_names = []\n",
        "    for row in response_dict['Row']:\n",
        "        file_path = row['FileRef']\n",
        "        file_name = row['FileLeafRef']\n",
        "        download_url = base_path2 + \"download.aspx?SourceUrl=\" + file_path\n",
        "        download_urls.append(download_url)\n",
        "\n",
        "    print(download_urls)\n",
        "    with open('urls.txt', 'w') as f:\n",
        "        f.writelines([url + '\\n' for url in download_urls])\n",
        "    !aria2c --header \"Cookie: {cookie}\" --summary-interval 10 --console-log-level=notice -c -x 16 -s 16 -k 1M  -d {folder} -i urls.txt\n",
        "\n",
        "\n",
        "#@markdown ä¿å­˜è·¯å¾„\n",
        "folder = \"/content/sample_sd\" #@param {type:\"string\"}\n",
        "folder = os.path.join(folder, \"\")\n",
        "link = \"\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "if \"sharepoint\" in link:\n",
        "  print(\"This is a Onedrive sharepoint link.\")\n",
        "  cookie = os.popen(f'curl -L {link} -A \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36\" -s -I | grep set-cookie | grep FedAuth | sed \"s/set-cookie: //\" | sed \"s/;.*//\"').read().strip()\n",
        "  if \":f:\" in link:\n",
        "    print(\"This is a folder link.\")\n",
        "    get_download_url_sp(link,cookie)\n",
        "  elif \":u:\" in link:\n",
        "    print(\"This is a file link.\")\n",
        "    direct_link = get_download_url(link)\n",
        "    print(direct_link)\n",
        "    !aria2c --header \"Cookie: {cookie}\" --summary-interval 10 --console-log-level=notice -c -x 16 -s 16 -k 1M \"{direct_link}\" -d {folder}\n",
        "  else:\n",
        "    print(\"Invalid link.\")\n",
        "else:\n",
        "    print(\"This is a Onedrive personal link.\")\n",
        "    if \"/u/\" in link:\n",
        "        print(\"This is a file link.\")\n",
        "        url = onelink(link)[0]\n",
        "        print(url)\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {url} -d {folder}\n",
        "    elif \"/f/\" in link:\n",
        "\n",
        "        print(\"This is a folder link.\")\n",
        "        decoded_url = urllib.parse.unquote(link)\n",
        "        print(decoded_url)\n",
        "        # å°†è¦è½¬æ¢çš„é“¾æ¥\n",
        "        decoded_url = \"https://onedrive.live.com/redir?resid=EB170A97A2E583E3!24655&authkey=!AE8inL5QvAG_sW4&ithint=folder\"\n",
        "        # ä»é“¾æ¥ä¸­æå–èµ„æºIDå’Œé¡¹ç›®ID\n",
        "        resource_id = re.search(r'resid=(.*?)!', decoded_url).group(1)\n",
        "        item_id = re.search(r'!(.*?)&', decoded_url).group(1)\n",
        "        # æ„å»ºè½¬æ¢åçš„é“¾æ¥\n",
        "        api_url = f\"https://api.onedrive.com/v1.0/drives/{resource_id}/items/{resource_id}!{item_id}/children?&authKey=!AE8inL5QvAG_sW4\"\n",
        "        print(api_url)\n",
        "        # å‘é€APIè¯·æ±‚ï¼Œè·å–å“åº”æ•°æ®\n",
        "        response = requests.get(api_url)\n",
        "        response_dict = response.json()\n",
        "        # è·å–æ‰€æœ‰æ–‡ä»¶çš„@content.downloadUrl\n",
        "        download_urls = []\n",
        "        for item in response_dict['value']:\n",
        "            download_url = item['@content.downloadUrl']\n",
        "            download_urls.append(download_url)\n",
        "\n",
        "        print(download_urls)\n",
        "        with open('urls.txt', 'w') as f:\n",
        "          f.writelines([url + '\\n' for url in download_urls])\n",
        "        !aria2c --summary-interval 10 --console-log-level=notice -c -x 16 -s 16 -k 1M  -d {folder} -i urls.txt\n",
        "    else:\n",
        "        print(\"Invalid link.\")"
      ],
      "metadata": {
        "id": "dKusiLb8MaIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (ç™¾åº¦ç½‘ç›˜ï¼‰ä¸‹è½½æˆ–ä¸Šä¼ "
      ],
      "metadata": {
        "id": "ZwL86mNVErqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.å®‰è£…ä¾èµ–\n",
        "!pip3 install Cython\n",
        "!pip3 install BaiduPCS-Py\n",
        "!pip3 install aget"
      ],
      "metadata": {
        "id": "dV7PyjC02kQ7",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.é“¾æ¥ç™¾åº¦ç½‘ç›˜\n",
        "from baidupcs_py.baidupcs import BaiduPCSApi\n",
        "from http.cookies import SimpleCookie\n",
        "#@markdown æ‰“å¼€ç™¾åº¦ç½‘ç›˜ï¼ŒF12æŸ¥çœ‹ç½‘ç»œè¯·æ±‚ï¼Œéšä¾¿æ‰“å¼€ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œå¤åˆ¶list?xxxè¯·æ±‚ä¸‹é¢çš„cookie,bdussåœ¨cookiesé‡Œé¢æœ‰\n",
        "cookies = \"\"  #@param {type:\"string\"}\n",
        "bduss = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "cookies_dict = {k.strip(): v.value for k, v in SimpleCookie(cookies).items()}\n",
        "\n",
        "print(cookies_dict)\n",
        "#@markdown è¿™é‡Œéšä¾¿åœ¨æ§åˆ¶å°è¾“ä¸ªä¸œè¥¿å›è½¦\n",
        "\n",
        "api = BaiduPCSApi(bduss=bduss, cookies=cookies_dict)\n",
        "!BaiduPCS-Py useradd --cookies \"{cookies}\" --bduss \"{bduss}\"\n",
        "!BaiduPCS-Py who"
      ],
      "metadata": {
        "id": "2d23qLaL5lhr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3.ä¸‹è½½\n",
        "import time\n",
        "import random\n",
        "import string\n",
        "import subprocess\n",
        "import os\n",
        "#@markdown å¤šçº¿ç¨‹æ‰¹é‡åå°ä¸‹è½½ï¼Œå¯ä»¥è‡ªå·±çœ‹ä¸‹è½½æ–‡ä»¶å¤¹è¿›åº¦\n",
        "#@markdown å¡«ç™¾åº¦ç½‘ç›˜æ–‡ä»¶å¤¹è·¯å¾„\n",
        "folder_path = \"/apps\" #@param {type:\"string\"}\n",
        "# pass = \"j3vk\" #@param {type:\"string\"}\n",
        "save_path = \"/content\" #@param {type:\"string\"}\n",
        "!BaiduPCS-Py ls -n -A \"{folder_path}\"\n",
        "# !BaiduPCS-Py download  {folder_path} -o {save_path}\n",
        "# !BaiduPCS-Py download -d aget_py {folder_path} -o {save_path}\n",
        "output = get_ipython().getoutput(f'BaiduPCS-Py ls -n -A \"{folder_path}\"')\n",
        "\n",
        "file_paths = [line[13:].strip() for line in output[3:]]\n",
        "print(file_paths)\n",
        "for file_path in file_paths:\n",
        "    with open(\"download_log1.txt\", \"a\") as log_file:\n",
        "      subprocess.Popen(['BaiduPCS-Py', 'download', '-d', 'aget_py', file_path, '-o', save_path], stdout=log_file, stderr=log_file)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vRWZ-ch8-XFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4.ä¸Šä¼ \n",
        "file_path = \"\" #@param {type:\"string\"}\n",
        "file_savepath = \"apps\" #@param {type:\"string\"}\n",
        "#@markdown çº¿ç¨‹æ•°ï¼Œç„å­¦å‚æ•°\n",
        "max_workers = 4 #@param {type:\"slider\", min:1, max:64, step:1}\n",
        "#@markdown å•æ–‡ä»¶ä¸Šä¼ æˆ–å¤šæ–‡ä»¶ä¸Šä¼ \n",
        "upload_type = \"One\" #@param [\"One\", \"Many\"]\n",
        "!BaiduPCS-Py upload --upload-type One --max-workers {max_workers}  {file_path} {file_savepath}"
      ],
      "metadata": {
        "id": "i6ZmCcpNPtwI",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ï¼ˆrcloneï¼‰ æŒ‚è½½å¤šç§äº‘ç›˜ï¼Œäº’ç›¸åŒæ­¥\n",
        "Modified from https://colab.research.google.com/github/shirooo39/MiXLab/blob/master/MiXLab.ipynb#scrollTo=3GKtYuBbUP-c"
      ],
      "metadata": {
        "id": "_Tay8w_PtbJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.å®‰è£…rclone\n",
        "import os\n",
        "# !curl https://rclone.org/install.sh | sudo bash\n",
        "# !sudo apt-get -y install fuse3\n",
        "!mkdir -p \"/root/.config/rclone\"\n"
      ],
      "metadata": {
        "id": "xbtQLGWNxNPy",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.é…ç½®rclone\n",
        "#@markdown å»ºè®®åœ¨æœ¬æœºé…ç½®åå†ä¸Šä¼ é…ç½®æ–‡ä»¶ï¼Œ<a href=\"https://rclone.org/downloads/\">ä¸‹è½½rcloneå®‰è£…åŒ…</a>è§£å‹ï¼Œåœ¨ç›®å½•ä¸‹æ•²å‘½ä»¤./rclone configï¼Œ<a href=\"https://hechuan.me/rclone-google-drive\">é…ç½®è¿‡ç¨‹</a>ï¼Œé…ç½®æ–‡ä»¶ä¿å­˜åœ¨C:\\Users\\xxx\\AppData\\Roaming\\rcloneï¼‰\n",
        "!rclone config"
      ],
      "metadata": {
        "cellView": "form",
        "id": "983XRXeAyvpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ï¼ˆå¯é€‰ï¼‰ä¸‹è½½/ä¸Šä¼ é…ç½®æ–‡ä»¶\n",
        "from google.colab import files\n",
        "is_upload = True #@param {type:\"boolean\"}\n",
        "if is_upload:\n",
        "  !rm /content/rclone.conf\n",
        "  uploaded = files.upload()\n",
        "  filepath = list(uploaded.keys())[0]\n",
        "  !mkdir -p \"/root/.config/rclone\"\n",
        "  !cp -f \"/content/{filepath}\" /root/.config/rclone\n",
        "else:\n",
        "  files.download('/root/.config/rclone/rclone.conf')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5TeliGhXu0Ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qakuMVVjQlGU"
      },
      "outputs": [],
      "source": [
        "#@title ï¼ˆå¯é€‰ï¼‰æŒ‚è½½åˆ°colab\n",
        "# ============================= FORM ============================= #\n",
        "Cache_Directory = \"DISK\" #@param [\"RAM\", \"DISK\"]\n",
        "# ================================================================ #\n",
        "\n",
        "import os\n",
        "from IPython.display import HTML, clear_output\n",
        "import uuid\n",
        "import ipywidgets as widgets\n",
        "from google.colab import output\n",
        "import re\n",
        "\n",
        "if not os.path.exists(\"/root/.ipython/mixlab.py\"):\n",
        "  from shlex import split as _spl\n",
        "  from subprocess import run\n",
        "\n",
        "  shellCmd = \"wget -qq https://shirooo39.github.io/MiXLab/resources/mixlab.py \\\n",
        "                  -O /root/.ipython/mixlab.py\"\n",
        "  run(_spl(shellCmd))\n",
        "\n",
        "from mixlab import (\n",
        "    runSh,\n",
        "    prepareSession,\n",
        "    rcloneConfigurationPath,\n",
        ")\n",
        "\n",
        "class MakeButton(object):\n",
        "  def __init__(self, title, callback, style):\n",
        "    self._title = title\n",
        "    self._callback = callback\n",
        "    self._style = style\n",
        "  def _repr_html_(self):\n",
        "    callback_id = 'button-' + str(uuid.uuid4())\n",
        "    output.register_callback(callback_id, self._callback)\n",
        "    if self._style != \"\":\n",
        "      style_html = \"p-Widget jupyter-widgets jupyter-button widget-button mod-\" + self._style\n",
        "    else:\n",
        "      style_html = \"p-Widget jupyter-widgets jupyter-button widget-button\"\n",
        "    template = \"\"\"<button class=\"{style_html}\" id=\"{callback_id}\">{title}</button>\n",
        "        <script>\n",
        "          document.querySelector(\"#{callback_id}\").onclick = (e) => {{\n",
        "            google.colab.kernel.invokeFunction('{callback_id}', [], {{}})\n",
        "            e.preventDefault();\n",
        "          }};\n",
        "        </script>\"\"\"\n",
        "    html = template.format(title=self._title, callback_id=callback_id, style_html=style_html)\n",
        "    return html\n",
        "\n",
        "def ShowAC():\n",
        "  clear_output(wait=True)\n",
        "  display(\n",
        "      widgets.HBox(\n",
        "          [widgets.VBox(\n",
        "              [widgets.HTML(\n",
        "                  '''<h3 style=\"font-family:Trebuchet MS;color:#4f8bd6;margin-top:0px;\">\n",
        "                  Available drive to mount/unmount:</h3>\n",
        "                  '''\n",
        "                  ),\n",
        "               mountNam]\n",
        "               )\n",
        "          ]\n",
        "          )\n",
        "      )\n",
        "\n",
        "  display(HTML(\"<br>\"), MakeButton(\"Mount\", MountCMD, \"primary\"),\n",
        "          MakeButton(\"Unmount\", unmountCMD, \"danger\"))\n",
        "\n",
        "prepareSession()\n",
        "content = open(f\"{rcloneConfigurationPath}/rclone.conf\").read()\n",
        "avCon = re.findall(r\"^\\[(.+)\\]$\", content, re.M)\n",
        "mountNam = widgets.Dropdown(options=avCon)\n",
        "\n",
        "if Cache_Directory == 'RAM':\n",
        "  cache_path = '/dev/shm'\n",
        "elif Cache_Directory == 'DISK':\n",
        "  os.makedirs('/tmp', exist_ok=True)\n",
        "  cache_path = '/tmp'\n",
        "\n",
        "def MountCMD():\n",
        "    mPoint = f\"/content/drives/{mountNam.value}\"\n",
        "    os.makedirs(mPoint, exist_ok=True)\n",
        "    cmd = rf\"rclone mount {mountNam.value}: {mPoint}\" \\\n",
        "      rf\" --config {rcloneConfigurationPath}/rclone.conf\" \\\n",
        "      ' --user-agent \"Mozilla\"' \\\n",
        "      ' --buffer-size 256M' \\\n",
        "      ' --transfers 10' \\\n",
        "      ' --vfs-cache-mode full' \\\n",
        "      ' --vfs-cache-max-age 0h0m1s' \\\n",
        "      ' --vfs-cache-poll-interval 0m1s' \\\n",
        "      f' --cache-dir {cache_path}' \\\n",
        "      ' --allow-other' \\\n",
        "      ' --daemon'\n",
        "\n",
        "    if runSh(cmd, shell=True) == 0:\n",
        "      print(f\"The drive have been successfully mounted! - \\t{mPoint}\")\n",
        "    else:\n",
        "      print(f\"Failed to mount the drive! - \\t{mPoint}\")\n",
        "\n",
        "def unmountCMD():\n",
        "  mPoint = f\"/content/drives/{mountNam.value}\"\n",
        "  if os.system(f\"fusermount -uz {mPoint}\") == 0:\n",
        "    runSh(f\"rm -r {mPoint}\")\n",
        "    print(f\"The drive have been successfully unmounted! - \\t{mPoint}\")\n",
        "  else:\n",
        "    runSh(f\"fusermount -uz {mPoint}\", output=True)\n",
        "\n",
        "ShowAC()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "t03ZdwQ-IvPv"
      },
      "outputs": [],
      "source": [
        "#@title 3.å¯åŠ¨rclone\n",
        "#@markdown å…·ä½“å‚æ•°è¯´æ˜è§å®˜æ–¹æ–‡æ¡£æˆ– <a href=\"https://ld246.com/article/1600853705300#%E5%85%B3%E4%BA%8E-rclone\">è¿™ä¸ªä¸­æ–‡æ–‡æ¡£</a>\n",
        "#@markdown ---\n",
        "#@markdown ---\n",
        "# ============================= FORM ============================= #\n",
        "# @markdown åŒæ­¥æ¨¡å¼ï¼šSyncå¯èƒ½ä¼šåˆ é™¤æ–‡ä»¶ï¼Œä½¿ç”¨å‰é€‰ä¸­Dry_Run(è¿è¡Œæµ‹è¯•)\n",
        "Mode = \"Copy\" #@param [\"Copy\", \"Move\", \"Sync\", \"Checker\", \"Deduplicate\", \"Remove Empty Directories\", \"Empty Trash\"]\n",
        "#@markdown é…ç½®æ—¶è¾“å…¥çš„åç§°:è·¯å¾„ï¼Œå¦‚ onedrive1:xxx/xxx\n",
        "Source = \"od:apk\" #@param {type:\"string\"}\n",
        "Destination = \"gd:test\" #@param {type:\"string\"}\n",
        "#@markdown ä»…è¿è¡Œæµ‹è¯•ï¼Œä¸ä¿®æ”¹æ–‡ä»¶\n",
        "Dry_Run = False #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown <center><h3><font color=\"#3399ff\"><b>âš™ï¸ Global Configuration âš™ï¸</b></font></h3></center>\n",
        "Extra_Arguments = \"\" #@param {type:\"string\"}\n",
        "Compare = \"Size & Mod-Time\" #@param [\"Size & Mod-Time\", \"Size & Checksum\", \"Only Mod-Time\", \"Only Size\", \"Only Checksum\"]\n",
        "#@markdown æœ€å¤§æ¯”è¾ƒæ–‡ä»¶çš„æ•°é‡å’ŒåŒæ­¥ä¼ è¾“çš„æ–‡ä»¶æ•°é‡ï¼Œè°ƒå¤§å¯èƒ½ä¼šè¢«é™åˆ¶\n",
        "Checkers = 12 #@param {type:\"slider\", min:1, max:40, step:1}\n",
        "Transfers = 12 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "Do_not_cross_filesystem_boundaries = False\n",
        "Do_not_update_modtime_if_files_are_identical = False #@param {type:\"boolean\"}\n",
        "Google_Drive_optimization = False #@param {type:\"boolean\"}\n",
        "Large_amount_of_files_optimization = False #@param {type:\"boolean\"}\n",
        "Simple_Ouput = True #@param {type:\"boolean\"}\n",
        "Skip_all_files_that_exist = False #@param {type:\"boolean\"}\n",
        "Skip_files_that_are_newer_on_the_destination = False #@param {type:\"boolean\"}\n",
        "Output_Log_File = \"OFF\" #@param [\"OFF\", \"NOTICE\", \"INFO\", \"ERROR\", \"DEBUG\"]\n",
        "\n",
        "#@markdown <br><center><h3><font color=\"#3399ff\"><b>â†ªï¸ Sync Configuration â†©ï¸</b></font></h3></center>\n",
        "Sync_Mode = \"Delete during transfer\" #@param [\"Delete during transfer\", \"Delete before transfering\", \"Delete after transfering\"]\n",
        "Track_Renames = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown <br><center><h3><font color=\"#3399ff\"><b>ğŸ’ Deduplicate Configuration ğŸ’</b></font></h3></center>\n",
        "Deduplicate_Mode = \"Interactive\" #@param [\"Interactive\", \"Skip\", \"First\", \"Newest\", \"Oldest\", \"Largest\", \"Rename\"]\n",
        "Deduplicate_Use_Trash = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "automatically_clear_cell_output = False  # @param{type: \"boolean\"}\n",
        "# ================================================================ #\n",
        "\n",
        "##### Importing the needed modules\n",
        "import os\n",
        "import IPython\n",
        "from IPython.display import HTML, clear_output\n",
        "\n",
        "\n",
        "##### Variable Declaration\n",
        "# Optimized for Google Colaboratory\n",
        "os.environ[\"bufferC\"] = \"--buffer-size 96M\"\n",
        "\n",
        "if Compare == \"Size & Checksum\":\n",
        "    os.environ[\"compareC\"] = \"-c\"\n",
        "elif Compare == \"Only Mod-Time\":\n",
        "    os.environ[\"compareC\"] = \"--ignore-size\"\n",
        "elif Compare == \"Only Size\":\n",
        "    os.environ[\"compareC\"] = \"--size-only\"\n",
        "elif Compare == \"Only Checksum\":\n",
        "    os.environ[\"compareC\"] = \"-c --ignore-size\"\n",
        "else:\n",
        "    os.environ[\"compareC\"] = \"\"\n",
        "\n",
        "os.environ[\"sourceC\"] = Source\n",
        "os.environ[\"destinationC\"] = Destination\n",
        "os.environ[\"transfersC\"] = \"--transfers \"+str(Transfers)\n",
        "os.environ[\"checkersC\"] = \"--checkers \"+str(Checkers)\n",
        "\n",
        "if Skip_files_that_are_newer_on_the_destination == True:\n",
        "    os.environ[\"skipnewC\"] = \"-u\"\n",
        "else:\n",
        "    os.environ[\"skipnewC\"] = \"\"\n",
        "\n",
        "if Skip_all_files_that_exist == True:\n",
        "    os.environ[\"skipexistC\"] = \"--ignore-existing\"\n",
        "else:\n",
        "    os.environ[\"skipexistC\"] = \"\"\n",
        "\n",
        "if Do_not_cross_filesystem_boundaries == True:\n",
        "    os.environ[\"nocrossfilesystemC\"] = \"--one-file-system\"\n",
        "else:\n",
        "    os.environ[\"nocrossfilesystemC\"] = \"\"\n",
        "\n",
        "if Do_not_update_modtime_if_files_are_identical == True:\n",
        "    os.environ[\"noupdatemodtimeC\"] = \"--no-update-modtime\"\n",
        "else:\n",
        "    os.environ[\"noupdatemodtimeC\"] = \"\"\n",
        "\n",
        "if Large_amount_of_files_optimization == True:\n",
        "    os.environ[\"filesoptimizeC\"] = \"--fast-list\"\n",
        "else:\n",
        "    os.environ[\"filesoptimizeC\"] = \"\"\n",
        "\n",
        "if Google_Drive_optimization == True:\n",
        "    os.environ[\"driveoptimizeC\"] = \"--drive-chunk-size 32M --drive-acknowledge-abuse --drive-keep-revision-forever\"\n",
        "else:\n",
        "    os.environ[\"driveoptimizeC\"] = \"\"\n",
        "\n",
        "if Dry_Run == True:\n",
        "    os.environ[\"dryrunC\"] = \"-n\"\n",
        "else:\n",
        "    os.environ[\"dryrunC\"] = \"\"\n",
        "\n",
        "if Output_Log_File != \"OFF\":\n",
        "    os.environ[\"statsC\"] = \"--log-file=/root/.rclone_log/rclone_log.txt\"\n",
        "else:\n",
        "    if Simple_Ouput == True:\n",
        "        os.environ[\"statsC\"] = \"-v --stats-one-line --stats=5s\"\n",
        "    else:\n",
        "        os.environ[\"statsC\"] = \"-v --stats=5s\"\n",
        "\n",
        "if Output_Log_File == \"INFO\":\n",
        "    os.environ[\"loglevelC\"] = \"--log-level INFO\"\n",
        "elif Output_Log_File == \"ERROR\":\n",
        "    os.environ[\"loglevelC\"] = \"--log-level ERROR\"\n",
        "elif Output_Log_File == \"DEBUG\":\n",
        "    os.environ[\"loglevelC\"] = \"--log-level DEBUG\"\n",
        "else:\n",
        "    os.environ[\"loglevelC\"] = \"\"\n",
        "\n",
        "os.environ[\"extraC\"] = Extra_Arguments\n",
        "\n",
        "if Sync_Mode == \"Delete during transfer\":\n",
        "    os.environ[\"syncmodeC\"] = \"--delete-during\"\n",
        "elif Sync_Mode == \"Delete before transfering\":\n",
        "    os.environ[\"syncmodeC\"] = \"--delete-before\"\n",
        "elif Sync_Mode == \"Delete after transfering\":\n",
        "    os.environ[\"syncmodeC\"] = \"--delete-after\"\n",
        "\n",
        "if Track_Renames == True:\n",
        "    os.environ[\"trackrenamesC\"] = \"--track-renames\"\n",
        "else:\n",
        "    os.environ[\"trackrenamesC\"] = \"\"\n",
        "\n",
        "if Deduplicate_Mode == \"Interactive\":\n",
        "    os.environ[\"deduplicateC\"] = \"interactive\"\n",
        "elif Deduplicate_Mode == \"Skip\":\n",
        "    os.environ[\"deduplicateC\"] = \"skip\"\n",
        "elif Deduplicate_Mode == \"First\":\n",
        "    os.environ[\"deduplicateC\"] = \"first\"\n",
        "elif Deduplicate_Mode == \"Newest\":\n",
        "    os.environ[\"deduplicateC\"] = \"newest\"\n",
        "elif Deduplicate_Mode == \"Oldest\":\n",
        "    os.environ[\"deduplicateC\"] = \"oldest\"\n",
        "elif Deduplicate_Mode == \"Largest\":\n",
        "    os.environ[\"deduplicateC\"] = \"largest\"\n",
        "elif Deduplicate_Mode == \"Rename\":\n",
        "    os.environ[\"deduplicateC\"] = \"rename\"\n",
        "\n",
        "\n",
        "if Deduplicate_Use_Trash == True:\n",
        "    os.environ[\"deduplicatetrashC\"] = \"\"\n",
        "else:\n",
        "    os.environ[\"deduplicatetrashC\"] = \"--drive-use-trash=false\"\n",
        "\n",
        "\n",
        "##### rclone Execution\n",
        "if Output_Log_File != \"OFF\" and Mode != \"Config\":\n",
        "    !mkdir -p -m 666 /root/.rclone_log/\n",
        "    display(HTML(\"<center><h2 style=\\\"font-family:Trebuchet MS;color:#ce2121;\\\">Logging enabled, rclone will no longer display any output on the terminal.<br>Please wait until the cell stop by itself.</h2></center><br>\"))\n",
        "\n",
        "if Mode == \"Copy\":\n",
        "    !rclone --config=/root/.config/rclone/rclone.conf copy \"$sourceC\" \"$destinationC\" $transfersC $checkersC $statsC $loglevelC $compareC $skipnewC $skipexistC $nocrossfilesystemC $noupdatemodtimeC $bufferC $filesoptimizeC $driveoptimizeC $dryrunC $extraC\n",
        "elif Mode == \"Move\":\n",
        "    !rclone --config=/root/.config/rclone/rclone.conf move \"$sourceC\" \"$destinationC\" $transfersC $checkersC $statsC $loglevelC --delete-empty-src-dirs $compareC $skipnewC $skipexistC $nocrossfilesystemC $noupdatemodtimeC $bufferC $filesoptimizeC $driveoptimizeC $dryrunC $extraC\n",
        "elif Mode == \"Sync\":\n",
        "    !rclone --config=/root/.config/rclone/rclone.conf sync \"$sourceC\" \"$destinationC\" $transfersC $checkersC $statsC $loglevelC $syncmodeC $trackrenamesC $compareC $skipnewC $skipexistC $nocrossfilesystemC $noupdatemodtimeC $bufferC $filesoptimizeC $driveoptimizeC $dryrunC $extraC\n",
        "elif Mode == \"Checker\":\n",
        "    !rclone --config=/root/.config/rclone/rclone.conf check \"$sourceC\" \"$destinationC\" $checkersC $statsC $loglevelC $compareC $skipnewC $skipexistC $nocrossfilesystemC $noupdatemodtimeC $bufferC $filesoptimizeC $driveoptimizeC $dryrunC $extraC\n",
        "elif Mode == \"Deduplicate\":\n",
        "    !rclone --config=/root/.config/rclone/rclone.conf dedupe \"$sourceC\" $checkersC $statsC $loglevelC --dedupe-mode $deduplicateC $deduplicatetrashC $compareC $skipnewC $skipexistC $nocrossfilesystemC $noupdatemodtimeC $bufferC $filesoptimizeC $driveoptimizeC $dryrunC $extraC\n",
        "elif Mode == \"Remove Empty Directories\":\n",
        "    !rclone --config=/root/.config/rclone/rclone.conf rmdirs \"$sourceC\" $statsC $loglevelC $dryrunC $extraC\n",
        "elif Mode == \"Empty Trash\":\n",
        "    !rclone --config=/root/.config/rclone/rclone.conf cleanup \"$sourceC\" $statsC $loglevelC $dryrunC $extraC\n",
        "else:\n",
        "  !rclone --config=/root/.config/rclone/rclone.conf copy \"$sourceC\" \"$destinationC\" $transfersC $checkersC $statsC $loglevelC $compareC $skipnewC $skipexistC $nocrossfilesystemC $noupdatemodtimeC $bufferC $filesoptimizeC $driveoptimizeC $dryrunC $extraC\n",
        "\n",
        "##### Log Output\n",
        "if Output_Log_File != \"OFF\" and Mode != \"Config\":\n",
        "\n",
        "    ##### Rename log file and output settings.\n",
        "    !mv /root/.rclone_log/rclone_log.txt /root/.rclone_log/rclone_log_$(date +%Y-%m-%d_%H.%M.%S).txt\n",
        "    with open(\"/root/.rclone_log/\" + Mode + \"_settings.txt\", \"w\") as f:\n",
        "        f.write(\"Mode: \" + Mode + \\\n",
        "            \"\\nCompare: \" + Compare + \\\n",
        "            \"\\nSource: \\\"\" + Source + \\\n",
        "            \"\\\"\\nDestination: \\\"\" + Destination + \\\n",
        "            \"\\\"\\nTransfers: \" + str(Transfers) + \\\n",
        "            \"\\nCheckers: \" + str(Checkers) + \\\n",
        "            \"\\nSkip files that are newer on the destination: \" + str(Skip_files_that_are_newer_on_the_destination) + \\\n",
        "            \"\\nSkip all files that exist: \" + str(Skip_all_files_that_exist) + \\\n",
        "            \"\\nDo not cross filesystem boundaries: \" + str(Do_not_cross_filesystem_boundaries) + \\\n",
        "            \"\\nDo not update modtime if files are identical: \" + str(Do_not_update_modtime_if_files_are_identical) + \\\n",
        "            \"\\nDry-Run: \" + str(Dry_Run) + \\\n",
        "            \"\\nOutput Log Level: \" + Output_Log_File + \\\n",
        "            \"\\nExtra Arguments: \\\"\" + Extra_Arguments + \\\n",
        "            \"\\\"\\nSync Moden: \" + Sync_Mode + \\\n",
        "            \"\\nTrack Renames: \" + str(Track_Renames) + \\\n",
        "            \"\\nDeduplicate Mode: \" + Deduplicate_Mode + \\\n",
        "            \"\\nDeduplicate Use Trash: \" + str(Deduplicate_Use_Trash))\n",
        "\n",
        "    ##### Compressing log file.\n",
        "    !rm -f /root/rclone_log.zip\n",
        "    !zip -r -q -j -9 /root/rclone_log.zip /root/.rclone_log/\n",
        "    !rm -rf /root/.rclone_log/\n",
        "    !mkdir -p -m 666 /root/.rclone_log/\n",
        "\n",
        "    ##### Send Log\n",
        "    if os.path.isfile(\"/root/rclone_log.zip\") == True:\n",
        "        try:\n",
        "            files.download(\"/root/rclone_log.zip\")\n",
        "            !rm -f /root/rclone_log.zip\n",
        "            display(HTML(\"<center><h2 style=\\\"font-family:Trebuchet MS;color:#446785;\\\">Sending log to your browser...</h2><br></center>\"))\n",
        "        except:\n",
        "            !mv /root/rclone_log.zip /content/rclone_log_$(date +%Y-%m-%d_%H.%M.%S).zip\n",
        "            display(HTML(\"<center><h2 style=\\\"font-family:Trebuchet MS;color:#446785;\\\">You can use file explorer to download the log file.</h2><br><img src=\\\"https://minormole.github.io/RcloneLab/res/rclonelab/01.png\\\"><br></center>\"))\n",
        "    else:\n",
        "        clear_output()\n",
        "        display(HTML(\"<center><h2 style=\\\"font-family:Trebuchet MS;color:#ce2121;\\\">There is no log file.</h2><br></center>\"))\n",
        "\n",
        "\n",
        "### Operation has been successfully completed.\n",
        "if Mode != \"Config\":\n",
        "    display(HTML(\"<center><h2 style=\\\"font-family:Trebuchet MS;color:#00b24c;\\\">âœ… Operation has been successfully completed.</h2><br></center>\"))\n",
        "\n",
        "\n",
        "##### Automatically clear terminal output if the checkbox's value on the top is set to True.\n",
        "if automatically_clear_cell_output is True:\n",
        "    clear_output()\n",
        "else:\n",
        "\tpass##### Automatically clear terminal output if the checkbox's value on the top is set to True.\n",
        "if automatically_clear_cell_output is True:\n",
        "    clear_output()\n",
        "else:\n",
        "\tpass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.å®‰è£…ä¾èµ–(2minå·¦å³ï¼Œä¸­é€”æœ‰ä¸ªè¾“å…¥å›½å®¶ä»£ç )\n",
        "!sudo apt install build-essential\n",
        "!sudo apt install libcurl4-openssl-dev\n",
        "!sudo apt install libsqlite3-dev\n",
        "!sudo apt install pkg-config\n",
        "!sudo apt install git\n",
        "!sudo apt install curl\n",
        "!sudo apt install libnotify-dev\n",
        "!echo 'deb http://download.opensuse.org/repositories/home:/npreining:/debian-ubuntu-onedrive/xUbuntu_20.04/ /' | sudo tee /etc/apt/sources.list.d/home:npreining:debian-ubuntu-onedrive.list\n",
        "!curl -fsSL https://download.opensuse.org/repositories/home:npreining:debian-ubuntu-onedrive/xUbuntu_20.04/Release.key | gpg --dearmor | sudo tee /etc/apt/trusted.gpg.d/home_npreining_debian-ubuntu-onedrive.gpg > /dev/null\n",
        "!sudo apt update\n",
        "!sudo apt install onedrive"
      ],
      "metadata": {
        "id": "zz05x_GBWmNJ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.é…ç½®æ–‡ä»¶\n",
        "!mkdir -p  /root/.config/onedrive\n",
        "!mkdir -p  /content/sample_data/GDrive_sync\n",
        "#@markdown é…ç½®æ–‡ä»¶è¯¦ç»†https://www.chuxin911.com/digital_management_onedrive_client_for_linux_20220227/\n",
        "#@markdown ### åŒæ­¥æ–¹å‘ï¼šcontent/sample_data/GDrive_sync ----> GDrive_sync\n",
        "#@markdown ### ä¸‹é¢æœ‰ä¸ªupload_only = \"true\"æ”¹æˆ\"false\"å°±æ˜¯åŒå‘åŒæ­¥\n",
        "config_content = '''# è®¾ç½®åŒæ­¥æ–‡ä»¶å¤¹ä½ç½®\n",
        "sync_dir = \"/content/sample_data\"\n",
        "\n",
        "# å¿½ç•¥æ‰€æœ‰éšè—æ–‡ä»¶å’Œæ–‡ä»¶å¤¹\n",
        "skip_dotfiles = \"true\"\n",
        "upload_only = \"true\"\n",
        "# æ˜¯å¦å•å‘ä¸Šä¼ \n",
        "no_remote_delete = \"true\"\n",
        "# æ˜¯å¦è®¾å®šä¸åˆ é™¤äº‘ç«¯æ–‡ä»¶,ä¸ºäº†äº‘ç«¯æ•°æ®å®‰å…¨'''\n",
        "sync_list = \"GDrive_sync\"\n",
        "with open('/content/config', 'w') as f:\n",
        "    f.write(config_content)\n",
        "with open('/content/sync_list', 'w') as f:\n",
        "    f.write(sync_list)\n",
        "!cp /content/config /root/.config/onedrive/config\n",
        "!cp /content/sync_list /root/.config/onedrive/sync_list\n"
      ],
      "metadata": {
        "id": "6YMf41aGZ0Ao",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3.å¼€å§‹åŒæ­¥\n",
        "!onedrive --synchronize --resync\n",
        "#@markdown æ›´æ–°é…ç½®æ–‡ä»¶ååŠ ä¸Šå‚æ•°--resync\n",
        "\n",
        "#@markdown éœ€è¦è¿æ¥OneDriveè´¦æˆ·,æŒ‰æŒ‡å¼•å¤åˆ¶æœ€åçš„é“¾æ¥å›è½¦"
      ],
      "metadata": {
        "id": "2ovcm7j0ko57",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ï¼ˆèµ„æºåˆ†æµï¼‰ä¸´æ—¶ä¸Šä¼ æ–‡ä»¶ï¼ˆåŒ…æ‹¬æ‰¹é‡ä¸Šä¼ ï¼‰\n",
        "* 1.bayfiles æ²¡æœ‰è¯´æ˜è¿‡æœŸæ—¶é—´ï¼ŒåŸºæœ¬æ²¡é™åˆ¶\n",
        "* 2.gofile å–å†³äºæœåŠ¡å™¨ï¼Œæ— æ´»è·ƒä¸‹è½½åå¤©ä¹‹å†…åˆ é™¤æ–‡ä»¶\n",
        "* æ–‡ä»¶åæœ‰;/\\.ä»€ä¹ˆå¥‡æ€ªå­—ç¬¦å¯èƒ½ä¸Šä¼ å¤±è´¥"
      ],
      "metadata": {
        "id": "XXcdFq4rujWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ä¸Šä¼ æ–‡ä»¶åˆ°https://bayfiles.com/\n",
        "#@markdown é€‰æ‹©ä¸Šä¼ è½½ç‚¹\n",
        "url = \"https://api.rapidshare.nu/upload\" #@param [\"https://api.openload.cc/upload\", \"https://api.bayfiles.com/upload\", \"https://api.lolabits.se/upload\", \"https://api.vshare.is/upload\", \"https://api.rapidshare.nu/upload\"] {allow-input: true}\n",
        "import requests\n",
        "import os\n",
        "import humanize\n",
        "#@markdown ä¸Šä¼ æ–‡ä»¶è·¯å¾„\n",
        "file_path = \"/content/sample_data/a.txt\"   #@param {type:\"string\"}\n",
        "file_name = os.path.basename(file_path)  # æ–‡ä»¶å\n",
        "file_size = os.path.getsize(file_path)  # æ–‡ä»¶å¤§å°\n",
        "response = requests.get(url)\n",
        "\n",
        "# å¼€å§‹ä¸Šä¼ \n",
        "with open(file_path, 'rb') as f:\n",
        "    files = {'file': (file_name, f)}\n",
        "    response = requests.post(url, files=files)\n",
        "\n",
        "# è¾“å‡ºç»“æœ\n",
        "url_short = response.json()['data']['file']['url']['short']\n",
        "print(f\"{url_short}, {humanize.naturalsize(file_size)}, filename={file_name}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IoJnQp_HUmsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ä¸Šä¼ æ–‡ä»¶å¤¹åˆ°https://bayfiles.com/\n",
        "import os\n",
        "import humanize\n",
        "#@markdown é€‰æ‹©ä¸Šä¼ è½½ç‚¹\n",
        "url = \"https://api.vshare.is/upload\" #@param [\"https://api.openload.cc/upload\", \"https://api.bayfiles.com/upload\", \"https://api.lolabits.se/upload\", \"https://api.vshare.is/upload\", \"https://api.rapidshare.nu/upload\"] {allow-input: true}\n",
        "folder_path = '/content/sample_data' #@param {type:\"string\"}\n",
        "\n",
        "# éå†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶\n",
        "for file_name in os.listdir(folder_path):\n",
        "    # æ„é€ æ–‡ä»¶è·¯å¾„\n",
        "    file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "    # å¦‚æœå½“å‰è·¯å¾„æ˜¯æ–‡ä»¶è€Œä¸æ˜¯æ–‡ä»¶å¤¹ï¼Œåˆ™ä¸‹è½½æ–‡ä»¶\n",
        "    if os.path.isfile(file_path):\n",
        "        # ä½¿ç”¨ curl å‘½ä»¤ä¸‹è½½æ–‡ä»¶\n",
        "        os.system(f'curl -F \"file=@{file_path}\" {url} -o output.json')\n",
        "        with open('output.json', 'r') as f:\n",
        "            s = f.read()\n",
        "\n",
        "        with open('results.txt', 'a') as f:\n",
        "            f.write(s + '\\n')\n",
        "\n",
        "import json\n",
        "\n",
        "# è¯»å–æ–‡ä»¶å†…å®¹\n",
        "with open('results.txt', 'r') as f:\n",
        "    content = f.readlines()\n",
        "\n",
        "# å­˜å‚¨æ‰€æœ‰ JSON å¯¹è±¡\n",
        "json_objects = []\n",
        "\n",
        "# é€è¡Œè§£æ JSON å¯¹è±¡\n",
        "current_json_object = ''\n",
        "for line in content:\n",
        "    if line.strip():  # å¦‚æœä¸æ˜¯ç©ºè¡Œï¼Œå°†å½“å‰è¡Œæ·»åŠ åˆ°å½“å‰ JSON å¯¹è±¡\n",
        "        current_json_object += line\n",
        "    else:  # å¦‚æœæ˜¯ç©ºè¡Œï¼Œè¡¨ç¤ºå½“å‰ JSON å¯¹è±¡å·²ç»è§£æå®Œæ¯•\n",
        "        json_objects.append(current_json_object)\n",
        "        current_json_object = ''\n",
        "\n",
        "# è§£ææ¯ä¸ª JSON å¯¹è±¡\n",
        "for json_object in json_objects:\n",
        "    data = json.loads(json_object)\n",
        "\n",
        "    # ä» Python å­—å…¸ä¸­æå–éœ€è¦çš„å€¼\n",
        "    url_short = data['data']['file']['url']['short']\n",
        "    size_bytes = data['data']['file']['metadata']['size']['bytes']\n",
        "    filename = data['data']['file']['metadata']['name']\n",
        "    print(f'{url_short}, {humanize.naturalsize(size_bytes)}, {filename}')\n",
        "    # print(\"----\")\n",
        "    # print(f'{url_short}')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fLfHBa9Ehtgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ä¸Šä¼ æ–‡ä»¶åˆ°https://gofile.io/\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "start_time = time.time()\n",
        "\n",
        "file_path = \"/content/sample_data/ansc.json\" #@param {type:\"string\"}\n",
        "file_size = os.path.getsize(file_path)\n",
        "print(\"æ–‡ä»¶å¤§å°ï¼š\"+str(file_size))\n",
        "response = requests.get('https://api.gofile.io/getServer')\n",
        "data = json.loads(response.text)\n",
        "server = data['data']['server']\n",
        "print(\"å½“å‰æœ€ä½³æœåŠ¡å™¨ï¼š\"+server)\n",
        "\n",
        "os.system(f'curl -F \"file=@{file_path}\" https://{server}.gofile.io/uploadFile -o output.json')\n",
        "!curl -F file=@{file_path} https://{server}.gofile.io/uploadFile -o output.json\n",
        "with open('output.json', 'r') as f:\n",
        "    s = f.read()\n",
        "\n",
        "data = json.loads(s)\n",
        "url = data['data']['downloadPage']\n",
        "print(url)\n",
        "\n",
        "\n",
        "end_time = time.time()  # è®°å½•ç»“æŸæ—¶é—´\n",
        "upload_time = end_time - start_time  # è®¡ç®—ä¸Šä¼ æ—¶é—´\n",
        "upload_speed = file_size / upload_time  # è®¡ç®—ä¸Šä¼ é€Ÿåº¦\n",
        "print(\"ä¸Šä¼ æ—¶é—´ï¼š{:.2f}ç§’\".format(upload_time))\n",
        "print(\"ä¸Šä¼ é€Ÿåº¦ï¼š{:.2f}MB/s\".format(upload_speed / 1024 / 1024))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XEeFoBMfc9Q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ä¸Šä¼ æ–‡ä»¶å¤¹åˆ°https://gofile.io/\n",
        "import json\n",
        "import os\n",
        "\n",
        "response = requests.get('https://api.gofile.io/getServer')\n",
        "data = json.loads(response.text)\n",
        "server = data['data']['server']\n",
        "print(\"å½“å‰æœ€ä½³æœåŠ¡å™¨ï¼š\"+server)\n",
        "folder_path = '/content/sample_data/GDrive_syn' #@param {type:\"string\"}\n",
        "\n",
        "# åˆ é™¤å·²å­˜åœ¨çš„è¾“å‡ºæ–‡ä»¶\n",
        "if os.path.exists('results_Gofile.txt'):\n",
        "    os.remove('results_Gofile.txt')\n",
        "flag = 0\n",
        "#@markdown æ³¨å†Œgofileæœ‰è‡ªå·±çš„tokenï¼Œè¯¦ç»†çœ‹é‚£è¾¹è¯´æ˜\n",
        "token = \"m2obcFWuuiXcTnMwgl7BkoIK3FsMKkAC\" #@param {type:\"string\"}\n",
        "# éå†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶\n",
        "for file_name in os.listdir(folder_path):\n",
        "    # æ„é€ æ–‡ä»¶è·¯å¾„\n",
        "    file_path = os.path.join(folder_path, file_name)\n",
        "    print(file_path)\n",
        "    # å¦‚æœå½“å‰è·¯å¾„æ˜¯æ–‡ä»¶è€Œä¸æ˜¯æ–‡ä»¶å¤¹ï¼Œåˆ™ä¸‹è½½æ–‡ä»¶\n",
        "    if os.path.isfile(file_path):\n",
        "        # ä½¿ç”¨ curl å‘½ä»¤ä¸‹è½½æ–‡ä»¶\n",
        "        if flag == 0:\n",
        "          os.system(f'curl -F token={token} -F \"file=@{file_path}\" https://{server}.gofile.io/uploadFile -o output.json')\n",
        "          with open('output.json', 'r') as f:\n",
        "              s = f.read()\n",
        "          data = json.loads(s)\n",
        "          folderId = data['data']['parentFolder']\n",
        "          print(folderId)\n",
        "          flag = 1\n",
        "        else:\n",
        "          print(\"i\")\n",
        "          os.system(f'curl -F \"file=@{file_path}\" -F token={token} -F folderId={folderId} https://{server}.gofile.io/uploadFile -o output.json')\n",
        "          with open('output.json', 'r') as f:\n",
        "              s = f.read()\n",
        "        with open('results_Gofile.txt', 'a') as f:\n",
        "            f.write(s + '\\n')\n",
        "\n",
        "# è¯»å–æ–‡ä»¶å†…å®¹\n",
        "with open('results_Gofile.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        # è§£æå½“å‰è¡Œçš„ JSON å¯¹è±¡\n",
        "        data = json.loads(line.strip())\n",
        "\n",
        "        # åœ¨è¿™é‡Œå¤„ç†è§£æå‡ºçš„æ•°æ®\n",
        "        # ä¾‹å¦‚æå–æŸä¸ªå­—æ®µçš„å€¼å¹¶æ‰“å°\n",
        "        url_short = data['data']['downloadPage']\n",
        "        file_name = data['data']['fileName']\n",
        "\n",
        "        print(f'url_short={url_short}, file_name={file_name}')\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4yZ_dNRTj7Q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <img class=\"logo-img\" width=\"32\" height=\"32\"  src=\"https://mega.io/wp-content/themes/megapages/megalib/images/megaicon.svg\" alt=\"MEGA Logo\" >ï¼ˆMegaï¼‰æ”¯æŒæ–‡ä»¶ã€æ–‡ä»¶å¤¹ä¸‹è½½\n",
        "From https://colab.research.google.com/github/shirooo39/MiXLab/blob/master/MiXLab.ipynb#scrollTo=3GKtYuBbUP-c"
      ],
      "metadata": {
        "id": "OHF8rRRfMy1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.ç›´æ¥ä¸‹è½½\n",
        "# ============================= FORM ============================= #\n",
        "URL = \"https://mega.nz/folder/9n5UTJSB#Hi50VqAs7V1r2m1tENZBJA\" #@param {type:\"string\"}\n",
        "OUTPUT_PATH = \"\" #@param {type:\"string\"}\n",
        "# @markdown > URL: Megaåˆ†äº«é“¾æ¥\n",
        "# @markdown > OUTPUT_PATHï¼šä¿å­˜è·¯å¾„\n",
        "# ================================================================ #\n",
        "\n",
        "import sys, os, urllib.request\n",
        "import time\n",
        "import subprocess\n",
        "import contextlib\n",
        "from IPython.display import clear_output\n",
        "\n",
        "HOME = os.path.expanduser(\"~\")\n",
        "if not os.path.exists(f\"{HOME}/.ipython/mixlab.py\"):\n",
        "    hCode = \"https://raw.githubusercontent.com/shirooo39/\" \\\n",
        "                \"MiXLab/master/resources/mixlab.py\"\n",
        "    urllib.request.urlretrieve(hCode, f\"{HOME}/.ipython/mixlab.py\")\n",
        "\n",
        "from mixlab import (\n",
        "    runSh,\n",
        "    loadingAn,\n",
        ")\n",
        "\n",
        "if not OUTPUT_PATH:\n",
        "  os.makedirs(\"downloads\", exist_ok=True)\n",
        "  OUTPUT_PATH = \"downloads\"\n",
        "# Installing MEGAcmd\n",
        "if not os.path.exists(\"/usr/bin/mega-cmd\"):\n",
        "    loadingAn()\n",
        "    print(\"Installing MEGA ...\")\n",
        "    runSh('sudo apt-get -y update')\n",
        "    runSh('sudo apt-get -y install libmms0 libc-ares2 libc6 libcrypto++6 libgcc1 libmediainfo0v5 libpcre3 libpcrecpp0v5 libssl1.1 libstdc++6 libzen0v5 zlib1g apt-transport-https')\n",
        "    runSh('sudo curl -sL -o /var/cache/apt/archives/MEGAcmd.deb https://mega.nz/linux/MEGAsync/Debian_9.0/amd64/megacmd-Debian_9.0_amd64.deb', output=True)\n",
        "    runSh('sudo dpkg -i /var/cache/apt/archives/MEGAcmd.deb', output=True)\n",
        "    print(\"MEGA is installed.\")\n",
        "    clear_output()\n",
        "\n",
        "# Unix, Windows and old Macintosh end-of-line\n",
        "newlines = ['\\n', '\\r\\n', '\\r']\n",
        "\n",
        "def unbuffered(proc, stream='stdout'):\n",
        "    stream = getattr(proc, stream)\n",
        "    with contextlib.closing(stream):\n",
        "        while True:\n",
        "            out = []\n",
        "            last = stream.read(1)\n",
        "            # Don't loop forever\n",
        "            if last == '' and proc.poll() is not None:\n",
        "                break\n",
        "            while last not in newlines:\n",
        "                # Don't loop forever\n",
        "                if last == '' and proc.poll() is not None:\n",
        "                    break\n",
        "                out.append(last)\n",
        "                last = stream.read(1)\n",
        "            out = ''.join(out)\n",
        "            yield out\n",
        "\n",
        "def transfare():\n",
        "    import codecs\n",
        "    decoder = codecs.getincrementaldecoder(\"UTF-8\")()\n",
        "    cmd = [\"mega-get\", URL, OUTPUT_PATH]\n",
        "    proc = subprocess.Popen(\n",
        "        cmd,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        # Make all end-of-lines '\\n'\n",
        "        universal_newlines=True,\n",
        "    )\n",
        "    for line in unbuffered(proc):\n",
        "        print(line)\n",
        "\n",
        "transfare()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NG6JPbsnMvPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.ç™»å½•Megaï¼ˆéœ€è¦ä¸Šä¼ æ–‡ä»¶æ—¶ï¼‰\n",
        "# ============================= FORM ============================= #\n",
        "# ================================================================ #\n",
        "\n",
        "from functools import wraps\n",
        "import errno\n",
        "import os\n",
        "import signal\n",
        "import subprocess\n",
        "import shlex\n",
        "\n",
        "class TimeoutError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def timeout(seconds=10, error_message=os.strerror(errno.ETIME)):\n",
        "    def decorator(func):\n",
        "        def _handle_timeout(signum, frame):\n",
        "            raise TimeoutError(error_message)\n",
        "\n",
        "        def wrapper(*args, **kwargs):\n",
        "            signal.signal(signal.SIGALRM, _handle_timeout)\n",
        "            signal.alarm(seconds)\n",
        "            try:\n",
        "                result = func(*args, **kwargs)\n",
        "            finally:\n",
        "                signal.alarm(0)\n",
        "            return result\n",
        "\n",
        "        return wraps(func)(wrapper)\n",
        "\n",
        "    return decorator\n",
        "\n",
        "if not os.path.exists(\"/root/.ipython/mixlab.py\"):\n",
        "    from subprocess import run\n",
        "    from shlex import split\n",
        "\n",
        "    shellCmd = \"wget -qq https://raw.githubusercontent.com/shirooo39/MiXLab/master/resources/mixlab.py \\\n",
        "                    -O /root/.ipython/mixlab.py\"\n",
        "    run(split(shellCmd))\n",
        "from mixlab import runSh\n",
        "\n",
        "@timeout(10)\n",
        "def runShT(args):\n",
        "    return runSh(args, output=True)\n",
        "\n",
        "# Installing MEGAcmd\n",
        "if not os.path.exists(\"/usr/bin/mega-cmd\"):\n",
        "    print(\"Installing MEGA ...\")\n",
        "    runSh('sudo apt-get -y update')\n",
        "    runSh('sudo apt-get -y install libmms0 libc-ares2 libc6 libcrypto++6 libgcc1 libmediainfo0v5 libpcre3 libpcrecpp0v5 libssl1.1 libstdc++6 libzen0v5 zlib1g apt-transport-https')\n",
        "    runSh('sudo curl -sL -o /var/cache/apt/archives/MEGAcmd.deb https://mega.nz/linux/MEGAsync/Debian_9.0/amd64/megacmd-Debian_9.0_amd64.deb', output=True)\n",
        "    runSh('sudo dpkg -i /var/cache/apt/archives/MEGAcmd.deb', output=True)\n",
        "    print(\"MEGA is installed.\")\n",
        "else:\n",
        "    !pkill mega-cmd\n",
        "\n",
        "# Enter MEGA credential\n",
        "USERNAME = \"\"  # @param {type:\"string\"}\n",
        "PASSWORD = \"\"  # @param {type:\"string\"}\n",
        "if not (USERNAME == \"\" or PASSWORD == \"\"):\n",
        "    try:\n",
        "        runShT(f\"mega-login {USERNAME} {PASSWORD}\")\n",
        "    except TimeoutError:\n",
        "        runSh('mega-whoami', output=True)\n",
        "else:\n",
        "    print(\"Please enter your MEGA credential.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "iflsOUKGOPYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.5.å‹ç¼©æ–‡ä»¶å¤¹ï¼ˆå¯é€‰ï¼‰\n",
        "import os, zipfile\n",
        "\n",
        "def make_zip(source_dir, output_filename):\n",
        "    zipf = zipfile.ZipFile(output_filename, 'w')\n",
        "    pre_len = len(os.path.dirname(source_dir))\n",
        "    for parent, dirnames, filenames in os.walk(source_dir):\n",
        "        for filename in filenames:\n",
        "            pathfile = os.path.join(parent, filename)\n",
        "            arcname = pathfile[pre_len:].strip(os.path.sep)     #ç›¸å¯¹è·¯å¾„\n",
        "            zipf.write(pathfile, arcname)\n",
        "    zipf.close()\n",
        "#@markdown  æŒ‡å®šè¦å‹ç¼©çš„æ–‡ä»¶å¤¹ï¼Œå·¦è¾¹å¤åˆ¶è·¯å¾„\n",
        "dir = \"/content/sample_data\" #@param {type:\"string\"}\n",
        "zipFile = f\"{dir}.zip\"\n",
        "make_zip(dir,zipFile)\n",
        "print(f\"å·²å‹ç¼©,{zipFile}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xN-KR_qhPtoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3.ä¸Šä¼ \n",
        "# ============================= FORM ============================= #\n",
        "# Simple_torrent = False  # @param{type: \"boolean\"}\n",
        "# Peerflix = False  # @param{type: \"boolean\"}\n",
        "PATH_TO_FILE = \"\" # @param {type:\"string\"}\n",
        "# @markdown > PATH_TO_FILEï¼šéœ€è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„\n",
        "# ================================================================ #\n",
        "\n",
        "import time\n",
        "import subprocess\n",
        "import contextlib\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Unix, Windows and old Macintosh end-of-line\n",
        "newlines = ['\\n', '\\r\\n', '\\r']\n",
        "\n",
        "def unbuffered(proc, stream='stdout'):\n",
        "    stream = getattr(proc, stream)\n",
        "    with contextlib.closing(stream):\n",
        "        while True:\n",
        "            out = []\n",
        "            last = stream.read(1)\n",
        "            # Don't loop forever\n",
        "            if last == '' and proc.poll() is not None:\n",
        "                break\n",
        "            while last not in newlines:\n",
        "                # Don't loop forever\n",
        "                if last == '' and proc.poll() is not None:\n",
        "                    break\n",
        "                out.append(last)\n",
        "                last = stream.read(1)\n",
        "            out = ''.join(out)\n",
        "            yield out\n",
        "\n",
        "def transfare():\n",
        "    cmd = \"\"\n",
        "    if Simple_torrent:\n",
        "        cmd = ['mega-put', 'downloads', '/colab']\n",
        "    elif Peerflix:\n",
        "        cmd = ['mega-put', 'peerflix', '/colab']\n",
        "    else:\n",
        "        cmd = ['mega-put', PATH_TO_FILE, '/colab']\n",
        "    proc = subprocess.Popen(\n",
        "        cmd,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        # Make all end-of-lines '\\n'\n",
        "        universal_newlines=True,\n",
        "    )\n",
        "    for line in unbuffered(proc):\n",
        "        clear_output(wait=True)\n",
        "        print(line)\n",
        "\n",
        "try:\n",
        "    transfare()\n",
        "except FileNotFoundError:\n",
        "    print(\"Please log into your MEGA account first!\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "C0wGFyufOlNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# kemono (megaé“¾æ¥åœ¨æ•°ç»„é‡Œé¢ï¼Œå› ä¸ºæœ‰ipæµé‡é™åˆ¶å¯èƒ½ä¼šå¤±è´¥)"
      ],
      "metadata": {
        "id": "KUdupygHDQP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title å®‰è£…ä¾èµ–\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "!apt-get -y install -qq aria2\n",
        "if not os.path.exists(\"/usr/bin/mega-cmd\"):\n",
        "    print(\"Installing MEGA ...\")\n",
        "    # !apt-get -y update\n",
        "    !apt-get -y install libmms0 libc-ares2 libc6 libcrypto++6 libgcc1 libmediainfo0v5 libpcre3 libpcrecpp0v5 libssl1.1 libstdc++6 libzen0v5 zlib1g apt-transport-https\n",
        "    !curl -sL -o /var/cache/apt/archives/MEGAcmd.deb https://mega.nz/linux/MEGAsync/Debian_9.0/amd64/megacmd-Debian_9.0_amd64.deb\n",
        "    !dpkg -i /var/cache/apt/archives/MEGAcmd.deb\n",
        "    clear_output()\n",
        "    print(\"MEGA is installed.\")"
      ],
      "metadata": {
        "id": "ePqUEZknnX-S",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title çˆ¬å–é¡µé¢\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import subprocess,sys,re\n",
        "import threading\n",
        "import time\n",
        "from urllib.parse import urlsplit, parse_qs, unquote\n",
        "import os\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "savepath = \"/content/0sss\"\n",
        "# savepath = os.path.join(savepath, \"\")\n",
        "mega_links = {}\n",
        "post_ids = []\n",
        "skip_id = []\n",
        "url = 'https://kemono.party/patreon/user/43005054'\n",
        "user_id = re.search(r'\\d+', url).group()\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "name = soup.find('span', {'itemprop': 'name'}).text.strip()\n",
        "\n",
        "def download_link(link, folder_path):\n",
        "    print(\"asdasd\")\n",
        "    parsed_link = urlsplit(link)\n",
        "    max_attempts = 20\n",
        "    attempt = 0\n",
        "    if \"mega\" in link:\n",
        "        mega_links[link] = folder_path\n",
        "        os.makedirs(folder_path, exist_ok=True)\n",
        "        # time.sleep(0.1)\n",
        "        # !mega-get {link} \"{folder_path}\"  # ä½¿ç”¨ megadl ä¸‹è½½é“¾æ¥\n",
        "    elif \"drive.google\" in link:\n",
        "        file_id = link.split(\"/\")[5]\n",
        "        print(f\"id========================{file_id}\")\n",
        "        if \"/folders/\" in link:\n",
        "          !gdown --fuzzy \"{file_id}\" -O \"{folder_path}\" --folder\n",
        "        else:\n",
        "          !gdown --fuzzy \"{file_id}\" -O \"{folder_path}\"  # ä½¿ç”¨ gdown ä¸‹è½½é“¾æ¥\n",
        "    elif \"dropbox\" in link:\n",
        "        url = parsed_link.scheme + \"://\" + parsed_link.netloc + parsed_link.path\n",
        "        if \"/sh/\" in link:\n",
        "          !wget -P \"{folder_path}\" -O \"archive.zip\" -c {url}\n",
        "        else:\n",
        "          !wget -P \"{folder_path}\" -c {url}\n",
        "    else:\n",
        "        while attempt < max_attempts:\n",
        "            query_string = parsed_link.query\n",
        "            params = parse_qs(query_string)\n",
        "            file_param = params['f'][0]\n",
        "            file_name = os.path.basename(file_param)\n",
        "            if os.path.isfile(os.path.join(folder_path, file_name)):\n",
        "                break\n",
        "            !aria2c --console-log-level=error -x 2 -s 2 --summary-interval 5 -d \"{folder_path}\" -o \"{file_name}\"  {link}\n",
        "            if os.path.isfile(os.path.join(folder_path, file_name)):\n",
        "                break\n",
        "            else:\n",
        "                attempt += 1\n",
        "                print(f\"Attempt {attempt} to download {link} failed, retrying...\")\n",
        "        else:\n",
        "            print(f\"Failed to download {link} after {max_attempts} attempts.\")\n",
        "# å¤„ç†å•é¡µçš„æŠ•ç¨¿ï¼Œæ¨é€åˆ°é˜Ÿåˆ—\n",
        "def process_page(url, queue):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    name = soup.find('span', {'itemprop': 'name'}).text.strip()\n",
        "    articles = soup.find_all('article', {'class': 'post-card'})\n",
        "    # è·å–æŠ•ç¨¿é“¾æ¥ï¼Œæ¨é€åˆ°é˜Ÿåˆ—\n",
        "    for article in articles:\n",
        "        post_id = re.search(r'\\d+$', article.find('a')['href']).group()\n",
        "        post_card_text = article.find('header', {'class': 'post-card__header'}).text.strip()\n",
        "        link = article.find('a')['href']\n",
        "        queue.put((link, post_id, post_card_text))\n",
        "\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def process_post(queue):\n",
        "    while True:\n",
        "        item = queue.get()\n",
        "        if item is None:\n",
        "            break\n",
        "        link, post_id, post_card_text = item\n",
        "        i = 0\n",
        "        response = requests.get('https://kemono.party' + link)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        post_content = soup.find('div', {'class': 'post__body'})\n",
        "        links = []\n",
        "        for link in post_content.find_all([\"a\", \"source\"]):\n",
        "            href = link.get(\"href\") or link.get(\"src\")\n",
        "            if href.startswith(\"http\") and \"fanbox.cc\" not in href:\n",
        "              if href.endswith((\".mp4\", \".webm\", \".wav\", \".m4p\", \".ogg\", \".pdf\", \".wav\", \".ogg\", \".jpg\", \".jpeg\", \".png\", \".gif\", \".zip\", \".rar\", \".7z\")) or any(x in href for x in [\"mega\", \"dropbox\", \"gofile\", \"drive\"]):\n",
        "                  links.append(href)\n",
        "              else:\n",
        "                  print(f\"Skipped link {href} for post {post_id} of link: {href}\")\n",
        "        # for p in post_content.find_all('p'):\n",
        "        #   links.append(p.text)\n",
        "        links_set = set(links)  # è½¬æ¢ä¸ºé›†åˆå»é‡\n",
        "        links = list(links_set)  # è½¬æ¢ä¸ºåˆ—è¡¨\n",
        "        post_card_text = post_card_text.replace('/', '_')\n",
        "        # å°†åŒå¼•å·æ›¿æ¢ä¸ºä¸­æ–‡çš„å¼•å·\n",
        "        post_card_text = post_card_text.replace('\"', 'â€œ')\n",
        "        print(f\"{len(links)}::{links}\")\n",
        "        with ThreadPoolExecutor(max_workers=8) as executor:\n",
        "          for link in links:\n",
        "              executor.submit(download_link, link, f\"{savepath}/{name}-{user_id}/{post_id}-{post_card_text}/\")\n",
        "        queue.task_done()\n",
        "\n",
        "import queue\n",
        "# åˆ›å»ºé˜Ÿåˆ—\n",
        "q = queue.Queue()\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "try:\n",
        "    text = soup.find('small').text.strip()\n",
        "    result = re.search(r'\\d+$', text)\n",
        "    pages = int(result.group()) // 50 + 1\n",
        "    for page in range(pages):\n",
        "      page_url = f\"{url}?o={page*50}\"\n",
        "      process_page(page_url,q)\n",
        "except AttributeError:\n",
        "    process_page(url,q)\n",
        "\n",
        "# process_page(url,q)\n",
        "\n",
        "# åˆ›å»ºçº¿ç¨‹æ± å¹¶ä¸‹è½½é“¾æ¥\n",
        "num_threads = 8\n",
        "threads = []\n",
        "for i in range(num_threads):\n",
        "    t = threading.Thread(target=process_post, args=(q,))\n",
        "    threads.append(t)\n",
        "    t.start()\n",
        "\n",
        "# ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ\n",
        "q.join()\n",
        "\n",
        "# åœæ­¢æ‰€æœ‰çº¿ç¨‹\n",
        "for i in range(num_threads):\n",
        "    q.put(None)\n",
        "for t in threads:\n",
        "    t.join()"
      ],
      "metadata": {
        "id": "TeYLANGYyapr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title mega\n",
        "mega_links = {\"https://mega.nz/#!4TZUWI6B!_Qxa8FNGmYTh9D4asOEIqEKBI6FWqEidnFrSRAFjaTw\":\"/content/221111\"}\n",
        "print(mega_links)\n",
        "import subprocess\n",
        "import contextlib,os\n",
        "newlines = ['\\n', '\\r\\n', '\\r']\n",
        "def unbuffered(proc, stream='stdout'):\n",
        "    stream = getattr(proc, stream)\n",
        "    with contextlib.closing(stream):\n",
        "        while True:\n",
        "            out = []\n",
        "            last = stream.read(1)\n",
        "            # Don't loop forever\n",
        "            if last == '' and proc.poll() is not None:\n",
        "                break\n",
        "            while last not in newlines:\n",
        "                # Don't loop forever\n",
        "                if last == '' and proc.poll() is not None:\n",
        "                    break\n",
        "                out.append(last)\n",
        "                last = stream.read(1)\n",
        "            out = ''.join(out)\n",
        "            yield out\n",
        "\n",
        "for link, folder_path in mega_links.items():\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "    print(link)\n",
        "    print(folder_path)\n",
        "    command = [\"mega-get\", link, folder_path]\n",
        "    proc = subprocess.Popen(command,stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        # Make all end-of-lines '\\n'\n",
        "        universal_newlines=True,)\n",
        "    print(proc)\n",
        "    counter = 0\n",
        "    for line in unbuffered(proc):\n",
        "        counter += 1\n",
        "        if counter % 20 == 0:\n",
        "            print(line)"
      ],
      "metadata": {
        "id": "g9Aq1QCmbLhe",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOyo5zf4suod"
      },
      "source": [
        "# å…¶ä»–å·¥å…·\n",
        "From https://colab.research.google.com/github/shirooo39/MiXLab/blob/master/MiXLab.ipynb#scrollTo=3GKtYuBbUP-c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYCRR-yWSuyi",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title <img src=\"https://img.icons8.com/color/100/000000/youtube-play.png\" width=\"32\" height=\"32\"  align=\"left\" alt=\"\"/>YouTube  è§†é¢‘ä¸‹è½½</font>\n",
        "# ============================= FORM ============================= #\n",
        "# @markdown <font size=5>ç›´æ¥è¿è¡Œï¼Œä¼šå‡ºç°ä¸‹è½½ç•Œé¢</font>\n",
        "Archive = False\n",
        "# ================================================================ #\n",
        "\n",
        "import os, uuid, urllib.parse\n",
        "import ipywidgets as widgets\n",
        "\n",
        "from glob import glob\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "from IPython.display import HTML, clear_output, YouTubeVideo\n",
        "from IPython.utils.io import ask_yes_no\n",
        "from google.colab import output, files\n",
        "\n",
        "Links = widgets.Textarea(placeholder='''Video/Playlist Link\n",
        "(one link per line)''')\n",
        "\n",
        "VideoQ = widgets.Dropdown(options=[\"Best Quality (VP9 upto 4K)\", \"Best Compatibility (H.264 upto 1080p)\"])\n",
        "\n",
        "AudioQ = widgets.Dropdown(options=[\"Best Quality (Opus)\", \"Best Compatibility (M4A)\"])\n",
        "\n",
        "Subtitle = widgets.ToggleButton(value=True, description=\"Subtitle\", button_style=\"info\", tooltip=\"Subtitle\")\n",
        "\n",
        "SavePathYT = widgets.Dropdown(options=[\"/content\", \"/content/downloads\"])\n",
        "\n",
        "AudioOnly = widgets.ToggleButton(value=False, description=\"Audio Only\", button_style=\"\", tooltip=\"Audio Only\")\n",
        "\n",
        "Resolution = widgets.Select(options=[\"Highest\", \"4K\", \"1440p\", \"1080p\", \"720p\", \"480p\", \"360p\", \"240p\", \"144p\"], value=\"Highest\")\n",
        "\n",
        "Extension = widgets.Select(options=[\"mkv\", \"webm\"], value=\"mkv\")\n",
        "\n",
        "UsernameYT = widgets.Text(placeholder=\"Username\")\n",
        "\n",
        "PasswordYT = widgets.Text(placeholder=\"Password\")\n",
        "\n",
        "SecAuth = widgets.Text(placeholder=\"2nd Factor Authentication\")\n",
        "\n",
        "VideoPW = widgets.Text(placeholder=\"Video Password\")\n",
        "\n",
        "GEOBypass = widgets.Dropdown(options=[\"Disable\", \"Hide\", \"AD\", \"AE\", \"AF\", \"AG\", \"AI\", \"AL\", \"AM\", \"AO\", \"AQ\", \"AR\", \"AS\", \"AT\", \"AU\", \"AW\", \"AX\", \"AZ\", \"BA\", \"BB\", \"BD\", \"BE\", \"BF\", \"BG\", \"BH\", \"BI\", \"BJ\", \"BL\", \"BM\", \"BN\", \"BO\", \"BQ\", \"BR\", \"BS\", \"BT\", \"BV\", \"BW\", \"BY\", \"BZ\", \"CA\", \"CC\", \"CD\", \"CF\", \"CG\", \"CH\", \"CI\", \"CK\", \"CL\", \"CM\", \"CN\", \"CO\", \"CR\", \"CU\", \"CV\", \"CW\", \"CX\", \"CY\", \"CZ\", \"DE\", \"DJ\", \"DK\", \"DM\", \"DO\", \"DZ\", \"EC\", \"EE\", \"EG\", \"EH\", \"ER\", \"ES\", \"ET\", \"FI\", \"FJ\", \"FK\", \"FM\", \"FO\", \"FR\", \"GA\", \"GB\", \"GD\", \"GE\", \"GF\", \"GG\", \"GH\", \"GI\", \"GL\", \"GM\", \"GN\", \"GP\", \"GQ\", \"GR\", \"GS\", \"GT\", \"GU\", \"GW\", \"GY\", \"HK\", \"HM\", \"HN\", \"HR\", \"HT\", \"HU\", \"ID\", \"IE\", \"IL\", \"IM\", \"IN\", \"IO\", \"IQ\", \"IR\", \"IS\", \"IT\", \"JE\", \"JM\", \"JO\", \"JP\", \"KE\", \"KG\", \"KH\", \"KI\", \"KM\", \"KN\", \"KP\", \"KR\", \"KW\", \"KY\", \"KZ\", \"LA\", \"LB\", \"LC\", \"LI\", \"LK\", \"LR\", \"LS\", \"LT\", \"LU\", \"LV\", \"LY\", \"MA\", \"MC\", \"MD\", \"ME\", \"MF\", \"MG\", \"MH\", \"MK\", \"ML\", \"MM\", \"MN\", \"MO\", \"MP\", \"MQ\", \"MR\", \"MS\", \"MT\", \"MU\", \"MV\", \"MW\", \"MX\", \"MY\", \"MZ\", \"NA\", \"NC\", \"NE\", \"NF\", \"NG\", \"NI\", \"NL\", \"NO\", \"NP\", \"NR\", \"NU\", \"NZ\", \"OM\", \"PA\", \"PE\", \"PF\", \"PG\", \"PH\", \"PK\", \"PL\", \"PM\", \"PN\", \"PR\", \"PS\", \"PT\", \"PW\", \"PY\", \"QA\", \"RE\", \"RO\", \"RS\", \"RU\", \"RW\", \"SA\", \"SB\", \"SC\", \"SD\", \"SE\", \"SG\", \"SH\", \"SI\", \"SJ\", \"SK\", \"SL\", \"SM\", \"SN\", \"SO\", \"SR\", \"SS\", \"ST\", \"SV\", \"SX\", \"SY\", \"SZ\", \"TC\", \"TD\", \"TF\", \"TG\", \"TH\", \"TJ\", \"TK\", \"TL\", \"TM\", \"TN\", \"TO\", \"TR\", \"TT\", \"TV\", \"TW\", \"TZ\", \"UA\", \"UG\", \"UM\", \"US\", \"UY\", \"UZ\", \"VA\", \"VC\", \"VE\", \"VG\", \"VI\", \"VN\", \"VU\", \"WF\", \"WS\", \"YE\", \"YT\", \"ZA\", \"ZM\", \"ZW\"])\n",
        "\n",
        "ProxyYT = widgets.Text(placeholder=\"Proxy URL\")\n",
        "\n",
        "MinSleep = widgets.BoundedIntText(value=0, min=0, max=300, step=1, description=\"Min:\")\n",
        "\n",
        "MaxSleep = widgets.BoundedIntText(value=0, min=0, max=300, step=1, description=\"Max:\")\n",
        "\n",
        "ExtraArg = widgets.Text(placeholder=\"Extra Arguments\")\n",
        "\n",
        "class MakeButton(object):\n",
        "  def __init__(self, title, callback, style):\n",
        "    self._title = title\n",
        "    self._callback = callback\n",
        "    self._style = style\n",
        "  def _repr_html_(self):\n",
        "    callback_id = 'button-' + str(uuid.uuid4())\n",
        "    output.register_callback(callback_id, self._callback)\n",
        "    if self._style != \"\":\n",
        "      style_html = \"p-Widget jupyter-widgets jupyter-button widget-button mod-\" + self._style\n",
        "    else:\n",
        "      style_html = \"p-Widget jupyter-widgets jupyter-button widget-button\"\n",
        "    template = \"\"\"<button class=\"{style_html}\" id=\"{callback_id}\">{title}</button>\n",
        "        <script>\n",
        "          document.querySelector(\"#{callback_id}\").onclick = (e) => {{\n",
        "            google.colab.kernel.invokeFunction('{callback_id}', [], {{}})\n",
        "            e.preventDefault();\n",
        "          }};\n",
        "        </script>\"\"\"\n",
        "    html = template.format(title=self._title, callback_id=callback_id, style_html=style_html)\n",
        "    return html\n",
        "\n",
        "def MakeLabel(description, button_style):\n",
        "  return widgets.Button(description=description, disabled=True, button_style=button_style)\n",
        "\n",
        "def upload_archive():\n",
        "  if ask_yes_no(\"Do you already have an archive file? (y/n)\", default=\"\", interrupt=\"\"):\n",
        "    try:\n",
        "      display(HTML(\"<h2 style=\\\"font-family:Trebuchet MS;color:#4f8bd6;\\\">Please upload an archive from your computer.</h2><br>\"))\n",
        "      UploadConfig = files.upload().keys()\n",
        "      clear_output(wait=True)\n",
        "      if len(UploadConfig) == 0:\n",
        "        return display(HTML(\"<center><h2 style=\\\"font-family:Trebuchet MS;color:#ce2121;\\\">File upload has been cancelled during upload file.</h2><br></center>\"))\n",
        "      elif len(UploadConfig) == 1:\n",
        "        for fn in UploadConfig:\n",
        "          if os.path.isfile(\"/content/\" + fn):\n",
        "            get_ipython().system_raw(\"mv -f \" + \"\\\"\" + fn + \"\\\" /root/.youtube-dl.txt && chmod 666 /root/.youtube-dl.txt\")\n",
        "            AudioOnly.observe(AudioOnlyChange)\n",
        "            Subtitle.observe(SubtitleChange)\n",
        "            AudioQ.observe(AudioQChange)\n",
        "            ShowYT()\n",
        "          else:\n",
        "            return display(HTML(\"<center><h2 style=\\\"font-family:Trebuchet MS;color:#ce2121;\\\">File upload has been failed during upload file.</h2><br></center>\"))\n",
        "      else:\n",
        "        for fn in UploadConfig:\n",
        "          get_ipython().system_raw(\"rm -f \" + \"\\\"\" + fn + \"\\\"\")\n",
        "        return display(HTML(\"<center><h2 style=\\\"font-family:Trebuchet MS;color:#ce2121;\\\">Please uploading only one file at a time.</h2><br></center>\"))\n",
        "    except:\n",
        "      clear_output(wait=True)\n",
        "      return display(HTML(\"<center><h2 style=\\\"font-family:Trebuchet MS;color:#ce2121;\\\">Error occurred during upload file.</h2><br></center>\"))\n",
        "  else:\n",
        "    get_ipython().system_raw(\"touch '/root/.youtube-dl.txt'\")\n",
        "    AudioOnly.observe(AudioOnlyChange)\n",
        "    Subtitle.observe(SubtitleChange)\n",
        "    AudioQ.observe(AudioQChange)\n",
        "    ShowYT()\n",
        "\n",
        "def RefreshPathYT():\n",
        "  if os.path.exists(\"/content/drive/\"):\n",
        "    if os.path.exists(\"/content/drive/Shared drives/\"):\n",
        "      SavePathYT.options = [\"/content\", \"/content/downloads\", \"/content/drive/My Drive\"] + glob(\"/content/drive/My Drive/*/\") + glob(\"/content/drive/Shared drives/*/\")\n",
        "    else:\n",
        "      SavePathYT.options = [\"/content\", \"/content/downloads\", \"/content/drive/My Drive\"] + glob(\"/content/drive/My Drive/*/\")\n",
        "  else:\n",
        "    SavePathYT.options = [\"/content\", \"/content/downloads\"]\n",
        "\n",
        "def AudioOnlyChange(change):\n",
        "  if change[\"type\"] == \"change\" and change[\"new\"]:\n",
        "    VideoQ.disabled = True\n",
        "    Subtitle.disabled = True\n",
        "    if Subtitle.value:\n",
        "      Subtitle.button_style = \"info\"\n",
        "    else:\n",
        "      Subtitle.button_style = \"\"\n",
        "    Resolution.disabled = True\n",
        "    Extension.options = [\"best\", \"aac\", \"flac\", \"mp3\", \"m4a\", \"opus\", \"vorbis\", \"wav\"]\n",
        "    Extension.value = \"best\"\n",
        "    AudioOnly.button_style = \"info\"\n",
        "  elif change[\"type\"] == \"change\" and change[\"new\"] == False:\n",
        "    VideoQ.disabled = False\n",
        "    Subtitle.disabled = False\n",
        "    if Subtitle.value:\n",
        "      Subtitle.button_style = \"info\"\n",
        "    else:\n",
        "      Subtitle.button_style = \"\"\n",
        "    Resolution.disabled = False\n",
        "    if AudioQ.value == \"Best Quality (Opus)\":\n",
        "      Extension.options = [\"mkv\", \"webm\"]\n",
        "    else:\n",
        "      Extension.options = [\"mkv\", \"mp4\", \"webm\"]\n",
        "    Extension.value = \"mkv\"\n",
        "    AudioOnly.button_style = \"\"\n",
        "\n",
        "def SubtitleChange(change):\n",
        "  if change[\"type\"] == \"change\" and change[\"new\"]:\n",
        "    Subtitle.button_style = \"info\"\n",
        "  elif change[\"type\"] == \"change\" and change[\"new\"] == False:\n",
        "    Subtitle.button_style = \"\"\n",
        "\n",
        "def AudioQChange(change):\n",
        "  if change[\"type\"] == \"change\" and change[\"new\"] == \"Best Quality (Opus)\":\n",
        "    Extension.options = [\"mkv\", \"webm\"]\n",
        "    Extension.value = \"mkv\"\n",
        "  elif change[\"type\"] == \"change\" and change[\"new\"] == \"Best Compatibility (M4A)\":\n",
        "    Extension.options = [\"mkv\", \"mp4\", \"webm\"]\n",
        "    Extension.value = \"mkv\"\n",
        "\n",
        "def ShowYT():\n",
        "  clear_output(wait=True)\n",
        "  RefreshPathYT()\n",
        "  display(widgets.HBox([widgets.VBox([widgets.HTML(\"<b style=\\\"color:#888888;\\\">Link:</b>\"), Links,\n",
        "                                      widgets.HTML(\"<b style=\\\"color:#888888;\\\">For website that require an account:</b>\"), UsernameYT, PasswordYT, SecAuth, VideoPW,\n",
        "                                      widgets.HTML(\"<b><a href=\\\"https://en.wikipedia.org/wiki/ISO_3166-1_alpha-2#Officially_assigned_code_elements\\\" target=\\\"_blank\\\">GEO Bypass Country:</a></b>\"), GEOBypass,\n",
        "                                      widgets.HTML(\"<b style=\\\"color:#888888;\\\">Proxy:</b>\"), ProxyYT,\n",
        "                                      widgets.HTML(\"<b style=\\\"color:#888888;\\\">Sleep Interval (second):</b>\"), MinSleep, MaxSleep]),\n",
        "                        widgets.VBox([widgets.HTML(\"<b style=\\\"color:#888888;\\\">Video Quality:</b>\"), VideoQ, widgets.HTML(\"<b style=\\\"color:#888888;\\\">Resolution:</b>\"), Resolution,\n",
        "                                      widgets.HTML(\"<b style=\\\"color:#888888;\\\">Audio Quality:</b>\"), AudioQ, widgets.HTML(\"<b style=\\\"color:#888888;\\\">Extension:</b>\"), Extension,\n",
        "                                      widgets.HTML(\"<b style=\\\"color:#888888;\\\">Extra Options:</b>\"), widgets.HBox([Subtitle, AudioOnly]),\n",
        "                                      widgets.HTML(\"<b style=\\\"color:#888888;\\\">Extra Arguments:</b>\"), ExtraArg])]), HTML(\"<h4 style=\\\"color:#888888;\\\">Save Location:</h4>\"),\n",
        "          SavePathYT, MakeButton(\"Refresh\", RefreshPathYT, \"\"))\n",
        "  if not os.path.exists(\"/content/drive/\"):\n",
        "#    display(HTML(\"*If you want to save in Google Drive please run the cell below.\"))\n",
        "    display(HTML(\"<br>\"), MakeButton(\"Download\", DownloadYT, \"info\"))\n",
        "\n",
        "def DownloadYT():\n",
        "  if Links.value.strip():\n",
        "    Count = 0\n",
        "    Total = str(len(Links.value.splitlines()))\n",
        "    # Account Check\n",
        "    if UsernameYT.value.strip() and PasswordYT.value.strip():\n",
        "      accountC = \"--username \\\"\" + UsernameYT.value + \"\\\" --password \\\"\" + PasswordYT.value + \"\\\"\"\n",
        "    else:\n",
        "      accountC = \"\"\n",
        "    if SecAuth.value.strip():\n",
        "      secauthC = \"-2 \" + SecAuth.value\n",
        "    else:\n",
        "      secauthC = \"\"\n",
        "    if VideoPW.value.strip():\n",
        "      videopwC = \"--video-password \" + VideoPW.value\n",
        "    else:\n",
        "      videopwC = \"\"\n",
        "    # Proxy\n",
        "    if ProxyYT.value.strip():\n",
        "      proxyytC = \"--proxy \" + ProxyYT.value\n",
        "    else:\n",
        "      proxyytC = \"\"\n",
        "    # GEO Bypass\n",
        "    if GEOBypass.value == \"Disable\":\n",
        "      geobypass = \"\"\n",
        "    elif GEOBypass.value == \"Hide\":\n",
        "      geobypass = \"--geo-bypass\"\n",
        "    else:\n",
        "      geobypass = \"--geo-bypass-country \" + GEOBypass.value\n",
        "    # Video Quality\n",
        "    if VideoQ.value == \"Best Quality (VP9 upto 4K)\":\n",
        "      videoqC = \"webm\"\n",
        "    else:\n",
        "      videoqC = \"mp4\"\n",
        "    # Audio Quality\n",
        "    if AudioQ.value == \"Best Quality (Opus)\":\n",
        "      audioqC = \"webm\"\n",
        "    else:\n",
        "      audioqC = \"m4a\"\n",
        "    # Audio Only Check\n",
        "    if AudioOnly.value:\n",
        "      subtitleC = \"\"\n",
        "      thumbnailC = \"\"\n",
        "      extC = \"-x --audio-quality 0 --audio-format \" + Extension.value\n",
        "      codecC = \"bestaudio[ext=\" + audioqC + \"]/bestaudio/best\"\n",
        "    else:\n",
        "      if Subtitle.value:\n",
        "        subtitleC = \"--all-subs --convert-subs srt --embed-subs\"\n",
        "      else:\n",
        "        subtitleC = \"\"\n",
        "      if Extension.value == \"mp4\":\n",
        "        thumbnailC = \"--embed-thumbnail\"\n",
        "      else:\n",
        "        thumbnailC = \"\"\n",
        "      extC = \"--merge-output-format \" + Extension.value\n",
        "      if Resolution.value == \"Highest\":\n",
        "        codecC = \"bestvideo[ext=\" + videoqC + \"]+bestaudio[ext=\" + audioqC + \"]/bestvideo+bestaudio/best\"\n",
        "      else:\n",
        "        codecC = \"bestvideo[ext=\" + videoqC + \",height<=\" + Resolution.value.replace(\"4K\", \"2160\").replace(\"p\", \"\") + \"]+bestaudio[ext=\" + audioqC + \"]/bestvideo[height<=\" + Resolution.value.replace(\"4K\", \"2160\").replace(\"p\", \"\") + \"]+bestaudio/bestvideo+bestaudio/best\"\n",
        "    # Archive\n",
        "    if os.path.isfile(\"/root/.youtube-dl.txt\"):\n",
        "      archiveC = \"--download-archive \\\"/root/.youtube-dl.txt\\\"\"\n",
        "    else:\n",
        "      archiveC = \"\"\n",
        "    # Sleep Interval\n",
        "    if MinSleep.value > 0 and MaxSleep.value > 0:\n",
        "      minsleepC = \"--min-sleep-interval \" + MinSleep.value\n",
        "      maxsleepC = \"--max-sleep-interval \" + MaxSleep.value\n",
        "    else:\n",
        "      minsleepC = \"\"\n",
        "      maxsleepC = \"\"\n",
        "    # Extra Arguments\n",
        "    extraargC = ExtraArg.value\n",
        "    for Link in Links.value.splitlines():\n",
        "      clear_output(wait=True)\n",
        "      Count += 1\n",
        "      display(HTML(\"<h3 style=\\\"font-family:Trebuchet MS;color:#4f8bd6;\\\">Processing link \" + str(Count) + \" out of \" + Total + \"</h3>\"))\n",
        "      if \"youtube.com\" in Link or \"youtu.be\" in Link:\n",
        "        display(HTML(\"<h3 style=\\\"font-family:Trebuchet MS;color:#4f8bd6;\\\">Currently downloading...</h3><br>\"), YouTubeVideo(Link, width=640, height=360), HTML(\"<br>\"))\n",
        "      else:\n",
        "        display(HTML(\"<h3 style=\\\"font-family:Trebuchet MS;color:#4f8bd6;\\\">Currently downloading <a href=\\\"\" + Link + \"\\\">\" + Link + \"</a></h3><br>\"))\n",
        "      if (\"youtube.com\" in Link or \"youtu.be\" in Link) and \"list=\" in Link:\n",
        "        !youtube-dl -i --no-warnings --yes-playlist --add-metadata $accountC $secauthC $videopwC $minsleepC $maxsleepC $geobypass $proxyytC $extC $thumbnailC $subtitleC $archiveC $extraargC -f \"$codecC\" -o \"/root/.YouTube-DL/%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s\" \"$Link\"\n",
        "      else:\n",
        "        !youtube-dl -i --no-warnings --yes-playlist --add-metadata $accountC $secauthC $videopwC $minsleepC $maxsleepC $geobypass $proxyytC $extC $thumbnailC $subtitleC $archiveC $extraargC -f \"$codecC\" -o \"/root/.YouTube-DL/%(title)s.%(ext)s\" \"$Link\"\n",
        "      if not os.path.exists(SavePathYT.value):\n",
        "        get_ipython().system_raw(\"mkdir -p -m 666 \" + SavePathYT.value)\n",
        "      get_ipython().system_raw(\"mv /root/.YouTube-DL/* '\" + SavePathYT.value + \"/'\")\n",
        "    # Archive Download\n",
        "    if os.path.isfile(\"/root/.youtube-dl.txt\"):\n",
        "      files.download(\"/root/.youtube-dl.txt\")\n",
        "    ShowYT()\n",
        "\n",
        "if not os.path.isfile(\"/usr/local/bin/youtube-dl\"):\n",
        "  get_ipython().system_raw(\"rm -rf /content/sample_data/ && mkdir -p -m 666 /root/.YouTube-DL/ && apt-get install atomicparsley && curl -L https://yt-dl.org/downloads/latest/youtube-dl -o /usr/local/bin/youtube-dl && chmod a+rx /usr/local/bin/youtube-dl\")\n",
        "if Archive:\n",
        "  upload_archive()\n",
        "else:\n",
        "  AudioOnly.observe(AudioOnlyChange)\n",
        "  Subtitle.observe(SubtitleChange)\n",
        "  AudioQ.observe(AudioQChange)\n",
        "  ShowYT()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zs0GpaqxevOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b4Igr8g0duu"
      },
      "source": [
        "### [iwaraè§†é¢‘ä¸‹è½½](https://github.com/hare1039/iwara-dl)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__PBrzCP0fPf",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# ==============================#============================== #\n",
        "# ==============================#============================== #\n",
        "#@title 1.å®‰è£…ä¾èµ–\n",
        "import glob\n",
        "import pathlib\n",
        "import shutil\n",
        "import subprocess\n",
        "from IPython.display import clear_output\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "iwara_download_list = []\n",
        "\n",
        "\n",
        "class IwaraDL:\n",
        "    def __init__(self):\n",
        "        self.main_path = pathlib.Path('/content/tools/iwara-dl')\n",
        "        self.download_path = self.main_path.joinpath('Downloads')\n",
        "        self.text_file_name = 'download.txt'\n",
        "        self.text_file_path = self.main_path.joinpath(self.text_file_name)\n",
        "\n",
        "        return None\n",
        "\n",
        "\n",
        "    def execute(self, command, show_output=False, cwd=None):\n",
        "        try:\n",
        "            with subprocess.Popen(command, shell=True, cwd=cwd,\n",
        "                stdout=subprocess.PIPE, stderr=subprocess.STDOUT,\n",
        "                bufsize=1, universal_newlines=True\n",
        "            ) as process:\n",
        "                if show_output is True:\n",
        "                    for line in process.stdout:\n",
        "                        print(line, end='')\n",
        "                else:\n",
        "                    pass\n",
        "        except Exception as unknown_error:\n",
        "            print(f'[Error]: {unknown_error}')\n",
        "\n",
        "            return exit\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "\n",
        "    def install(self):\n",
        "        # clone_path = str(self.main_path)\n",
        "        install_command = [\n",
        "            'apt -y install jq',\n",
        "            'apt -y install python3-bs4',\n",
        "            f'git clone https://github.com/hare1039/iwara-dl.git {self.main_path}'\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            for command in install_command:\n",
        "                self.execute(command, show_output=False)\n",
        "                subprocess.run(command, shell=True)\n",
        "        except Exception as unknown_error:\n",
        "            print(f'[Error]: {unknown_error}')\n",
        "\n",
        "            return exit\n",
        "        else:\n",
        "            self.download_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            return None\n",
        "\n",
        "\n",
        "    def add_download_url(self):\n",
        "        while True:\n",
        "            clear_output()\n",
        "\n",
        "            print('Type in a URL or \"exit\" to stop...\\n')\n",
        "            new_url = input('URL: ')\n",
        "\n",
        "            if new_url == 'exit':\n",
        "                clear_output()\n",
        "\n",
        "                break\n",
        "            elif new_url == '':\n",
        "                continue\n",
        "            else:\n",
        "                iwara_download_list.append(new_url)\n",
        "\n",
        "        return None\n",
        "\n",
        "\n",
        "    def add_download_file(self):\n",
        "        try:\n",
        "            self.text_file_path.unlink()\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        for filename in uploaded.keys():\n",
        "            shutil.move(filename, self.text_file_path)\n",
        "\n",
        "            clear_output()\n",
        "\n",
        "            print(f'Moved \"{filename}\" into \"{self.text_file_path}\"')\n",
        "\n",
        "        try:\n",
        "            with open(self.text_file_path, 'r', encoding='UTF-8') as txt_file:\n",
        "                global iwara_download_list\n",
        "\n",
        "                file = txt_file.read()\n",
        "                iwara_download_list.append(file)\n",
        "        except Exception as unknown_error:\n",
        "            print(f'[Error]: {unknown_error}')\n",
        "\n",
        "            return exit\n",
        "        finally:\n",
        "            txt_file.close()\n",
        "\n",
        "\n",
        "    def show_download_list(self):\n",
        "        if not iwara_download_list:\n",
        "            print('The download list is empty.')\n",
        "        else:\n",
        "            print(*iwara_download_list, sep='\\n')\n",
        "\n",
        "        return None\n",
        "\n",
        "\n",
        "    def clear_download_list(self):\n",
        "        iwara_download_list.clear()\n",
        "\n",
        "        return None\n",
        "\n",
        "\n",
        "    def purge_download_folder(self):\n",
        "        files = glob.glob(f'{self.download_path}/*')\n",
        "\n",
        "        try:\n",
        "            for f in files:\n",
        "                pathlib.Path(f).unlink()\n",
        "        except Exception as unknown_error:\n",
        "            print(f'[Error]: {unknown_error}')\n",
        "\n",
        "            return exit\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    IwaraDL().install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkMWKQVJ93Du"
      },
      "outputs": [],
      "source": [
        "# ------------------------------#------------------------------ #\n",
        "#@title 2.æ·»åŠ ä¸‹è½½é“¾æ¥\n",
        "#@markdown <font size='5'>Add downloads from URL or 'download.txt'</font>\n",
        "command = 'add_download_from_url' #@param ['add_download_from_url', 'add_download_from_file', 'show_download_list', 'clear_download_list', 'purge_download_folder']\n",
        "# ------------------------------#------------------------------ #\n",
        "#@markdown æ³¨æ„é“¾æ¥ä¸è¦åŒ…å«ç”¨æˆ·åï¼Œhttps://www.iwara.tv/video/zYiWkPQc7SbVza/gangbang åˆ æ‰åé¢/gangbang\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "def main():\n",
        "    command_list = [\n",
        "        'add_download_from_url', 'add_download_from_file',\n",
        "        'show_download_list', 'clear_download_list',\n",
        "        'purge_download_folder'\n",
        "    ]\n",
        "\n",
        "    if command == command_list[0]:\n",
        "        IwaraDL().add_download_url()\n",
        "    elif command == command_list[1]:\n",
        "        IwaraDL().add_download_file()\n",
        "    elif command == command_list[2]:\n",
        "        IwaraDL().show_download_list()\n",
        "    elif command == command_list[3]:\n",
        "        IwaraDL().clear_download_list()\n",
        "    elif command == command_list[4]:\n",
        "        IwaraDL().purge_download_folder()\n",
        "    else:\n",
        "        pass\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        main()\n",
        "    except KeyboardInterrupt:\n",
        "        clear_output()\n",
        "\n",
        "        exit\n",
        "    except NameError:\n",
        "        print('[Error]: Please make sure you have already run the cell \"[Install] ecchi.iwara-dl\" first!')\n",
        "\n",
        "        exit\n",
        "    except Exception as unknown_error:\n",
        "        print(f'[Error]: {unknown_error}')\n",
        "\n",
        "        exit\n",
        "    else:\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lLU9f0EH0mZN"
      },
      "outputs": [],
      "source": [
        "# ------------------------------#------------------------------ #\n",
        "#@title 3.å¼€å§‹ä¸‹è½½\n",
        "\n",
        "#@markdown Downloads are stored in \"/content/tools/iwara-dl/Downloads\"\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown <font size='5'><center>Options</center></font>\n",
        "hide_progress = False #@param {type:\"boolean\"}\n",
        "download_username = False #@param {type:\"boolean\"}\n",
        "clear_list_on_finish = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown > The option 'download_username'' treats the download list as username.<br>\n",
        "#@markdown > Tick this option if you want to download a whole collection from a username.\n",
        "#@markdown >\n",
        "#@markdown > For example:<br>\n",
        "#@markdown > To download everything (video only) from username \"AutumnJelly\", add the username --> autumnjelly <-- into the download list and tick this option. Only type in the username and not the full url: ecchi.iwara.tv/users/autumnjelly\n",
        "#@markdown >\n",
        "#@markdown > Do NOT mix the download list with URL and/or Username! That might break the downloader!\n",
        "# ------------------------------#------------------------------ #\n",
        "\n",
        "import pathlib\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "def main():\n",
        "    clear_output()\n",
        "\n",
        "    main_path = pathlib.Path('/content/tools/iwara-dl')\n",
        "    dl_path = main_path.joinpath('Downloads')\n",
        "\n",
        "    if not iwara_download_list:\n",
        "        print('The download list is empty.')\n",
        "    else:\n",
        "        if hide_progress is True:\n",
        "            n = '-n'\n",
        "        else:\n",
        "            n = ''\n",
        "\n",
        "        if download_username is True:\n",
        "            tc = '-t -c'\n",
        "\n",
        "            for dir in iwara_download_list:\n",
        "                dl_path.joinpath(dir).mkdir(parents=True, exist_ok=True)\n",
        "        else:\n",
        "            tc = ''\n",
        "\n",
        "        for downloads in iwara_download_list:\n",
        "            IwaraDL().execute(f'bash /content/tools/iwara-dl/iwara-dl.sh {tc} {n} {downloads}', show_output=True, cwd=dl_path)\n",
        "\n",
        "        if clear_list_on_finish is True:\n",
        "            iwara_download_list.clear()\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        main()\n",
        "    except KeyboardInterrupt:\n",
        "        clear_output()\n",
        "        exit\n",
        "    except Exception as unknown_error:\n",
        "        print(f'[Error]: {unknown_error}')\n",
        "        exit\n",
        "    else:\n",
        "        pass"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "_Tay8w_PtbJE",
        "aEVUiiRinMMJ",
        "XXcdFq4rujWa",
        "OHF8rRRfMy1j"
      ],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}